---
title: 'Lab10: Regressão Linear Múltipla'
author: "Ivandson Praeiro de Sousa"
date: "2023-01-13"
output:
  rmdformats::readthedown
  # html_document:
  # number_sections: no
  #   toc: yes
  #   toc_float: yes
  #   theme: cerulean
  #   df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```


## Introdução


Lembre-se de que exploramos a regressão linear simples examinando dados de beisebol da temporada de 2011 da *Major League Baseball* (MLB). Também usaremos esses dados para explorar a regressão múltipla. Nossa inspiração para explorar esses dados vem do filme Moneyball , que enfocou a “busca pelo segredo do sucesso no beisebol”. Ele segue uma equipe de baixo orçamento, o Oakland Athletics, que acreditava que estatísticas subutilizadas, como a capacidade de um jogador chegar à base, predizem melhor a capacidade de marcar pontos do que estatísticas típicas como *home runs*, *RBIs* (corridas impulsionadas) e média de rebatidas. Conseguir jogadores que se destacassem nessas estatísticas pouco aproveitadas acabou sendo muito mais acessível para o time.

Neste laboratório, veremos os dados de todos os 30 times da Liga Principal de Beisebol e examinaremos a relação linear entre as pontos marcados em uma temporada e várias estatísticas de outros jogadores. Nosso objetivo será encontrar o modelo que melhor prevê os pontos de uma equipe em uma temporada. Também pretendemos encontrar o modelo que melhor prevê o total de vitórias de uma equipe em uma temporada. O primeiro modelo nos diria em quais estatísticas do jogador devemos prestar atenção se quisermos obter pontos e o segundo modelo indicaria quais estatísticas do jogador devemos utilizar quando desejamos obter vitórias.



```{r}
library(ggplot2)
library(plyr)
library(tidyr)
library(dplyr)
library(DescTools)
library(htmltools)
library(knitr)
library(rmarkdown)
library(combinat)
library(kableExtra) #Para gerar tabelas com um layout agradável
library(leaps) #Para regressão linear múltipla
```


## Conteúdos abordados neste laboratório


* Regressão Linear Múltipla
* Otimização
* Intervalos de Confiança



## Os dados


Vamos carregar os dados para a temporada de 2011:


```{r}
download.file("http://www.openintro.org/stat/data/mlb11.RData", destfile = "mlb11.RData")
load("mlb11.RData")
```


Além dos pontos marcados (`runs`), este conjunto de dados contém sete variáveis tradicionalmente utilizadas: vez ao taco (`at_bats`), rebatidas (`hits`), rebatidas para fora do campo (`homeruns`), média de rebatidas (`bat_avg`), eliminações (`strikeouts`), bases roubadas (`stolen_bases`), e vitórias (`wins`). Também foram incluídas três novas variáveis: percentual de alcance de base (`new_onbase`), percentual de potência (`new_slug`), e alcance de base mais potência (`new_obs`). Para a primeira parte da análise vamos considerar as sete variáveis tradicionais. Ao final do laboratório, você trabalhará sozinho com as variáveis mais recentes.


Também gostaríamos de modificar os dados para facilitar o trabalho durante a seleção do modelo. Removemos a variável `team` do conjunto de dados e armazenamos a versão atualizada em `mlb11_wins`.


```{r}
mlb11_wins = mlb11 %>%
  select(-team)
```


Como `wins` não é uma estatística a nível de jogador - pelo menos para não arremessadores - não queremos usá-la ao prever `runs`. Portanto, vamos criar outro conjunto de dados modificado para utilizar ao tentar encontrar o melhor modelo para prever o número total de pontos marcados por uma equipe durante uma temporada. O inverso não é um problema ao tentar prever o número de vitórias de um time em uma temporada - `runs` pode ser usado para prever `wins`.


```{r}
mlb11_runs = mlb11_wins %>%
  select(-wins)
```


Conforme discutido em aula, há muitas maneiras de selecionar o modelo. Veremos a seguir alguns métodos de seleção. 


## A busca pelo melhor modelo


Conforme discutido em aula, há muitas maneiras de selecionar o modelo. Veremos os métodos de seleção direto e reverso, os quais utilizam critérios diferentes ($R_{adj}^2$, p-valor ou AIC).


### Previsão dos pontos marcados usando seleção reversa


O primeiro passo na seleção reversa é definir um modelo completo. Como criamos um conjunto de dados modificado para prever os pontos marcados, podemos usar um atalho, `runs ~ .`, para dizer ao R para usar todas as variáveis restantes para prever pontos.


```{r}
runs_full = lm(runs ~ ., data = mlb11_runs)
summary(runs_full)
```



> Exercício 1: Quantas variáveis estão sendo usadas para prever `runs` no modelo completo? Quantos parâmetros estão sendo estimados no modelo completo? Quantos dos parâmetros são significativamente diferentes de 0 no nível 0,05? qual é o $R^2_{adj}$ do modelo completo?


Conforme a saída do último trecho de código, 9 variáveis estão sendo consideradas no modelo como preditoras de `runs`, ao passo que 10 parâmetros estão sendo estimados, já que o modelo linear envolve também um termo constante (intercepto). 

De acordo com o modelo ajustado, apenas um parâmetro é significativo no nível de 0,05, que é o coeficiente do termo `stolen_bases`.

O $R^2_{adj}$ do modelo é igual a 0,9464 e, conforme já estudado no livro-texto, é um indicador da qualidade do ajuste, também conhecido como *coeficiente de explicação* do modelo, e nos mostra a proporção da variância na variável resposta que é explicada pelas variáveis independentes. Aqui, é importante fazer uma observação quanto à diferença entre o $R^2$ e o $R^2_{adj}$.

O $R^2$ sempre aumenta quando inserimos uma nova variável independente. O $R_{adj}^2$, por outro lado, apenas irá aumentar se a variável inserida for significativa. 


Agora que temos um modelo completo definido, podemos fazer a seleção do modelo reverso. A função `step()` torna extremamente fácil usar o AIC (Akiake's Information Criterion) para seleção de modelo. Semelhantemente ao $R^2_{adj}$, o AIC aplica uma penalidade aos modelos que usam mais variáveis preditoras.

Usaremos o trecho de código a seguir para determinar o melhor modelo para prever os pontos de uma equipe em uma temporada usando seleção regressiva com AIC como critério (observe que um AIC mais baixo indica um modelo melhor).


```{r}
runs_backAIC = step(runs_full, direction = "backward")
summary(runs_backAIC)
```



> Exercício 2: Quantos passos a seleção reversa usando AIC realizou antes de selecionar um modelo? Qual variável foi a primeira a ser removida? Quais variáveis acabaram no modelo final? Quantos parâmetros estão sendo estimados neste modelo final? Quantos dos parâmetros neste modelo final são significativamente diferentes de 0 no nível 0,05? Este modelo final tem um maior $R^2_{adj}$ do que o modelo completo para `runs`?


Conforme a saída do código acima, vemos que foram executados 4 passos até chegar-se no modelo supostamente mais adequado. A primeira variável removida foi `new_onbase`, ao passo que no modelo final restaram 5 das 9 variáveis. Como no modelo linear geralmente existe o termo `intercept`, 6 parâmetros estão sendo estimados no modelo resultante. Contudo, apenas 3 dos 6 parâmetros restantes são significativamente diferentes de zero no nível de 0,05.


O modelo resultante após a aplicação do AIC tem um $R^2_{adj}$ ligeiramente maior do que o modelo completo.


Agora, em vez de AIC, vamos usar o valor de $R^2_{adj}$ como nosso critério ao conduzir a seleção reversa. Lembre-se de que um valor mais alto de $R^2_{adj}$ indica um modelo melhor. Assim, começaremos com o modelo completo e, a cada passo, retiraremos uma variável do modelo.


```{r}
# Step 1
data.frame(
  modelo = c("completo", "-at_bats", "-hits", "-homeruns", "-bat_avg", "-strikeouts", "-stolen_bases", "-new_onbase", "-new_slug", "-new_obs"),
  adj_rsq = c(
    summary(lm(runs ~ . , mlb11_runs))$adj.r,
    summary(lm(runs ~ . - at_bats, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - hits, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - homeruns, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - bat_avg, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - strikeouts, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - stolen_bases, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_slug, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_obs, mlb11_runs))$adj.r
  )
) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
  )
```


Uma vez que o modelo que removeu `new_onbase` tem o maior $R^2_{adj}$, passamos para a etapa 2 usando esse modelo e continuamos removendo uma variável por vez e calculamos o novo $R^2_{adj}$ para cada modelo.
 

```{r}
# Step 2
data.frame(
  modelo = c("-new_onbase", "-new_onbase-at_bats", "-new_onbase-hits", "-new_onbase-homeruns", "-new_onbase-bat_avg", "-new_onbase-strikeouts", "-new_onbase-stolen_bases", "-new_onbase-new_slug", "-new_onbase-new_obs"),
  adj_rsq = c(
    summary(lm(runs ~ . - new_onbase, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - at_bats, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - hits, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - homeruns, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - bat_avg, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - stolen_bases, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - new_slug, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - new_obs, mlb11_runs))$adj.r
  )
) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
  )
```


Como o modelo que apresenta o maior $R^2_{adj}$ na etapa 2 é aquele que removeu a variável `strikeouts`, passamos para a etapa 3 usando o modelo que agora tem ambos `new_onbase` e `strikeouts` removidos e continuamos removendo uma variável por vez e calculando o novo valor $R^2_{adj}$ para cada modelo.



```{r}
# Step 3
data.frame(
  modelo = c("-new_onbase-strikeouts", "-new_onbase-strikeouts-at_bats", "-new_onbase-strikeouts-hits", "-new_onbase-strikeouts-homeruns", "-new_onbase-strikeouts-bat_avg", "-new_onbase-strikeouts-stolen_bases", "-new_onbase-strikeouts-new_slug", "-new_onbase-strikeouts-new_obs"),
  adj_rsq = c(
    summary(lm(runs ~ . - new_onbase - strikeouts, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts - at_bats, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts - hits, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts - homeruns, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts - bat_avg, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts - stolen_bases, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts - new_slug, mlb11_runs))$adj.r,
    summary(lm(runs ~ . - new_onbase - strikeouts - new_obs, mlb11_runs))$adj.r
  )
) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
  )
```



Como nenhum dos modelos que retira mais uma variável adicional do modelo que já exclui ambas `new_onbase` e `strikeouts` tem maior $R^2_{adj}$, paramos o processo e agora temos um modelo final. No código abaixo, armazenamos o modelo final e vemos um resumo do modelo final.



```{r}
runs_backADJr = lm(runs ~ . - new_onbase - strikeouts, mlb11_runs)
summary(runs_backADJr)
```



> Exercício 3: Quais variáveis acabaram no modelo final ao usar a seleção reversa com

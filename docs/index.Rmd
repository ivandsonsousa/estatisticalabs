---
title: "Laboratórios de Estatística Básica com R"
author: "Ivandson Praeiro de Sousa"
date: "22/11/2022"
output:
  rmdformats::readthedown
  # html_document:
  # number_sections: no
  #   toc: yes
  #   toc_float: yes
  #   theme: cerulean
  #   df_print: paged
bibliography: bibliografia.bib
csl: abnt.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```


# Sobre o projeto 


Este curso é uma adaptação dos laboratórios de estatística disponíveis no livro **OpenIntro Statistics: Labs for R** [@openintro]. Aqui, usamos as principais biliotecas do R para desenvolver aquilo que é proposto nos capítulos (laboratórios) do livro. Em cada caso, usamos também gráficos e tabelas para auxiliar no aprendizado dos conceitos estatísticos  envolvidos.

Todas as análises realizadas neste livro são subsidiadas por bases de dados reais, públicas, disponibilizadas pelos autores do livro [@datasets]. Além disso, como bibliografia complementar, utilizamos o livro-texto de Estatística Básica dos autores Bussab & Morettin [@bussab_morettin].

Por fim, ressaltamos que o livro está em contínuo desenvolvimento e, dessa forma, melhorias podem ser implementadas a qualquer momento. No mesmo aspecto, sugestões são sempre bem vindas.


# Lab01: Introdução ao R e ao Rstudio


O R é um poderoso software estatístico. Com ele, é possível fazer desde cálculos simples envolvendo distribuições de probabilidades e estatística descritiva até o desenvolvimento de modelos de machine learning. 

A linguagem R foi desenvolvida na década de 90 por dois estatísticos Neozelandêses, Ross Ihaka e Robert Gentleman (daí o nome R). O R é um software livre e de código aberto. Atualmente possui uma vasta biblioteca de funções para cálculos estatísticos e possui uma grande comunidade que contribui com o projeto [@rproject].

As distribuições linux geralmente já contêm o R. Para as demais, o software pode ser baixado através da página do projeto: <https://cran.r-project.org/>.

O Rstudio, por sua vez, é uma IDE (Integrated Development Enviroment) ou Ambiente de Desenvolvimento Integrado. Genericamente falando, uma IDE é um programa que, com sua interface gráfica amigável (mais parecida com os programas voltados ao usuário comum), traz uma série de ferramentas que facilitam o desenvolvimento de aplicações. Algumas dessas ferramentas são compilador e um editor de código-fonte capaz de apontar erros e sugerir a sintáxe correta das funções [@wikipediaIDE]. 

O Rstudio, a exemplo do R, também é um software gratuito e de código aberto. Porém, diferentemente do R, esta IDE possui também uma versão paga. Para baixar a ferramenta, basta acessar a página oficial: <https://posit.co/download/rstudio-desktop/>.



## Conteúdos abordados neste laboratório

* Primeiros passos no R e no Rstudio
* Explorando uma base de dados carregada da nuvem
* fazendo filtros e gráficos com o R


## Carregamento de pacotes

O R é uma linguagem de programação de código aberto, o que significa que os usuários podem contribuir com pacotes que facilitam nossas vidas. Ainda melhor, podemos usá-las gratuitamente. Para este laboratório, e muitos outros futuros, usaremos principalmente os seguintes pacotes do R:

* `dplyr`: para descrição de dados
* `ggplot2`: para visualização de dados
* `kableExtra`: Para deixar as saídas de dados em formato de tabela
* `rmarkdown`: para fazer relatórios como este, usando markdown

Para carregá-los no nosso ambiente de trabalho, digitamos no console:

```{r}
library(ggplot2)
library(plyr)
library(tidyr)
library(dplyr)
library(DescTools)
library(htmltools)
library(knitr)
library(rmarkdown)
library(combinat)
library(kableExtra) #Para gerar tabelas com um layout agradável
```

## Os dados: Registros de batismos do Dr. Arbuthnot

Aqui, vamos carregar os dados diretamente da itnernet, na página do *OpenIntro Statistics*:

```{r}
source("http://www.openintro.org/stat/data/arbuthnot.R")
```

O conjunto de dados Arbuthnot se refere ao Dr. John Arbuthnot, um médico, escritor e matemático do século 18. Ele se interessou pela razão ente o número de meninos e meninas recém-nascidos, e para isso ele coletou os registros de batismo de crianças nascidas em Londres no período compreendido entre 1629 e 1710. Vamos começar dando uma olhada nos dados, com o auxílio da função `head()`:

```{r}
arbuthnot %>%
  head(10) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Podemos ver as dimensões desse banco de dados

```{r}
dim(arbuthnot)
```

Para ver os nomes das variáveis observadas (colunas), fazemos:

```{r}
names(arbuthnot)
```

## Explorando os dados

Nós podemos acessar separadamente os dados de uma única coluna da base de dados da seguinte forma:

```{r}
arbuthnot$boys
```

```{r}
arbuthnot$girls
```

Nesse caso, os dados são impressos em tela como vetores, e não como um banco de dados estruturado.

O R tem algumas funções poderosas para criar gráficos. Podemos criar um gráfico simples do número de meninas batizadas por ano com o comando


```{r}
arbuthnot %>%
  ggplot(aes(x = year, y = girls)) + 
  geom_point(size = 2, col = "red") +
  labs(
    title = "Registros de nascimento do dr. Arbuthnot"
  ) +
  theme(text = element_text(size = 16))
```


Podemos também fazer um gráfico de linhas, ao invés de plotar os pontos dispersos:


```{r}
arbuthnot %>%
  ggplot(aes(x = year, y = girls)) + 
  geom_line(linewidth = 1, col = "red") +
  labs(
    title = "Registros de nascimento do dr. Arbuthnot"
  ) +
  theme(text = element_text(size = 16))
```

## Há alguma tendência aparente no número de meninas batizadas ao longo dos anos? Como você a descreveria? 

Para saber o número total de crianças batizadas em cada ano, fazemos:

```{r}
arbuthnot$boys + arbuthnot$girls
```

Nesse caso, visualizamos um vetor com 82 entradas, cada uma contendo a soma do número de meninos e de meninas batizados no respectivo ano. Nós podemos ainda utilizar este vetor para gerar alguns gráficos, então iremos salvá-lo como uma coluna permanente do nosso banco de dados:

```{r}
arbuthnot = mutate(arbuthnot, total = boys + girls)

arbuthnot %>%
  head(10) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Assim, uma nova coluna chamada "total" foi incluída no banco de dados. Podemos criar um gráfico do número total de batismos por ano com o comando:


```{r}
arbuthnot %>%
  ggplot(aes(x = year, y = total)) + 
  geom_line(linewidth = 1, col = "orange") +
  labs(
    title = "Registros de nascimento do dr. Arbuthnot"
  ) +
  theme(text = element_text(size = 16))
```

Podemos também calcular a proporção do número de meninos batizados em relação ao número de meninas batizadas em cada ano:

```{r}
arbuthnot$boys / arbuthnot$girls
```

Podemos também calcular a proporção de meninos batizados ano a ano em relação ao total de crianças batizadas no respectivo ano:

```{r}
arbuthnot$boys / (arbuthnot$boys + arbuthnot$girls)
```

Vamos usar novamente a função `mutate`para incluir uma nova coluna em nosso conjunto de dados para a proporção do número de meninos em relação ao total de recém-nascidos em cada ano:

```{r}
arbuthnot = mutate(arbuthnot, ratio_boys = arbuthnot$boys / arbuthnot$total)

arbuthnot %>%
  head(10) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Podemos também fazer um gráfico da proporção de meninos batizados relativo ao total ano a ano:


```{r}
arbuthnot %>%
  ggplot(aes(x = year, y = ratio_boys)) + 
  geom_line(linewidth = 1, col = "skyblue") +
  labs(
    title = "Porporção de meninos batizados"
  ) +
  theme(text = element_text(size = 16))
```

Nesse caso, percebe-se que a proporção de meninos oscila em torno de 50%.

Podemos ainda criar uma variável lógica que indica se o número de meninos nascidos é maior que o número de meninas:

```{r}
arbuthnot = mutate(arbuthnot, more_boys = boys > girls)

arbuthnot %>%
  head(10) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

## Um novo conjunto de dados: registros atuais de nascimento nos Estados Unidos

Vamos agora trabalhar com um conjunto de dados obtido mais recentemente. Primeiro, carregamos o dataframe:

```{r}
source("http://www.openintro.org/stat/data/present.R")
```

1. Quais anos estão incluídos nesse conjuntos de dados? 

```{r}
names(present)
```

```{r}
present$year
```

Vemos então que os anos incluídos vão de 1940 a 2002.

2. Quais as dimensões da base de dados? 

```{r}
dim(present)
```

3. Quais sãos os nomes das colunas ou variáveis?

```{r}
names(present)
```

4. Como esses dados se comparam aos de Arbuthnot? Eles estão em uma escala similar?


```{r}
present %>%
  ggplot(aes(x = year, y = girls)) + 
  geom_point(size = 2, col = "red") +
  labs(
    title = "Registros de nascimento atuais"
  ) +
  theme(text = element_text(size = 16))
```


```{r}
cat("Intervalo de anos para os dados do dr. Arbuthnot:", 
    c(min(arbuthnot$year), max(arbuthnot$year)),
    "\nIntervalo de anos para os dados atuais:",
    c(min(present$year), max(present$year))
    )
```
Como podemos ver a partir do resultado do gráfico acima, bem como com a saída da função `cat()`, os dados dos conjuntos `arbuthnot` e `present` estão em escalas diferentes. No caso dos dados do dr. Arbuthnot, o número de batismos de menina, por exemplo, está na escala de alguns milhares, ao passo que no conjunto de dados atual, esse número está na escala de milhão. Além disso, o intervalo temporal de coleta dos dois conjuntos de dados são também diferentes.

5. Crie um gráfico que mostre a proporção de meninos em relação às meninas para cada ano do conjunto de dados. O que você vê? A observação de Arbuthnot de que os meninos nascem numa proporção maior do que as meninas se mantém nos EUA?


```{r}
present = mutate(present, ratio_boys_girls = present$boys/present$girls)
```

```{r}
present %>%
  ggplot(aes(x = year, y = ratio_boys_girls)) + 
  geom_line(linewidth = 1, col = "orange") +
  labs(
    title = "Razão entre o número de meninos e de meninas",
    subtitle = "Conjunto de dados atual."
  ) +
  theme(text = element_text(size = 16))
```

Conforme podemos ver na saída do comando abaixo, a observação de Arbuthnot se mantêm nos EUA, embora o gráfico acima nos mostre que a razão entre o número de meninos e de meninas nascidos vem caindo ao longo das décadas, se aproximando de 1.

```{r}
present$meninos > present$meninas
```

Outra maneira de ver se existe algum ano no qual o número de meninos nascidos é menor do que o número de meninas é fazendo um filtro no dataframe:

```{r}
present[present$boys < present$girls, ]
```

Como vemos, a saída é vazia, tendo apenas os nomes das variáveis, sem qualquer observação nas linhas.

6. Em qual ano se verifica o maior número de nascimentos nos EUA? **Dica**: primeiramente calcule o total e salve em uma nova variável. Então, ordene seu banco de dados em ordem decrescente na colula total. Você pode fazer isso interativamente no seu *Data Viewer*, clicando nas flechas próximas aos nomes das variáveis.

Primeiro, vamos acrescentar a coluna "Total" ao nosso dataframe. 

```{r}
present = mutate(present, Total = present$boys + present$girls)
```

Em seguida, vamos aplicar um filtro ao dataframe, assim como fizemos acima, e mostrar todas as colunas do dataframe, porém apenas a linha correspondente ao valor máximo da coluna **Total**:

```{r}
present[present$Total == max(present$Total), ] 
```

Uma maneira mais elegante de fazer esse filtro é por meio da função `subset()`:


```{r}
present%>%
  subset(Total == max(Total))
```

Por outro lado, para responder à mesma pergunta e mostrar apenas as colunas **ano** e **Total**, na linha correspondente ao total máximo, fazemos:


```{r}
present[present$Total == max(present$Total), c('year', 'Total')]
```

Ou, por meio da função `select()`:

```{r}
present%>%
  subset(Total == max(Total), select = c("year", "Total"))
```

Esses dados são provenientes de uma pesquisa realizada pelo Centro de Controle de Doenças (Center For Disease Control) [Link do Artigo](http://www.cdc.gov/nchs/data/nvsr/nvsr53/nvsr53_20.pdf).




# Lab02: Introdução à Análise de Dados


Algumas pessoas definem a Estatística como a ciência que tem por objetivo transformar informação em conhecimento. O primeiro passo no processo é sumarizar e descrever a informação bruta - os dados. Neste laboratório, você obterá novos conhecimentos sobre saúde pública gerando sumários gráficos e numéricos de um conjunto de dados coletados pelo Centro para o Controle e Prevenção de Doenças (Centers for Disease Control and Prevention, CDC). Como esse conjunto de dados é extenso, ao longo do caminho você também aprenderá as habilidades indispensáveis de processamento de dados e organização de subconjuntos.


## Conteúdos abordados neste laboratório

* Histogramas
* Estatísticas descritivas
* Tabelas de contingência
* Aprofundando a biblioteca `dplyr`
* Observando relações entre duas variáveis quantitativas
* Observando relações entre duas variáveis qualitativas
* Observando relações entre uma variável qualitativa e uma quantitativa
* Box plots
* Distribuição normal


## Carregamento e detalhamento dos dados

O Sistema de Monitoramento de Fatores de Risco Comportamental (Behavioral Risk Factor Surveillance System, BRFSS) é uma pesquisa anual realizada por telefone com 350.000 pessoas nos Estados Unidos. Como seu nome implica, o BRFSS foi desenvolvido para identificar fatores de risco na população adulta e relatar tendências emergentes na saúde. Por exemplo, os respondentes são indagados sobre sua dieta e atividades físicas semanais, seu diagnóstico de HIV/AIDS, uso provável de tabaco, e mesmo seu nível de cobertura por planos de saúde. O website do BRFSS <http://www.cdc.gov/brfss> contém uma descrição completa desta pesquisa, incluindo as questões que motivaram o estudo e muitos resultados interessantes derivados dos dados.

Nós focaremos em uma amostra aleatória de 20.000 pessoas do BRFSS conduzida em 2000. Ainda que existam mais de 200 variáveis neste conjunto de dados, nós trabalharemos com um subconjunto menor.

Começamos importando os dados das 20.000 observações para dentro do espaço de trabalho do R. Depois de inicializar o RStudio, entre com o seguinte comando:

```{r}
source("http://www.openintro.org/stat/data/cdc.R")
```

O conjunto de dados `cdc` que aparece em seu espaço de trabalho é uma matriz de dados, onde cada linha representa um caso e cada coluna representa uma `variável`. Lembre-se que o R denomina este formato de dados como banco de dados (data frame), que será um termo utilizado ao longo dos laboratórios.

Para visualizar o nome das variáveis, digite o comando:

```{r}
names(cdc)
```

Ainda, nosso banco de dados tem `r nrow(cdc)` indivíduos entrevistados, sendo `r nrow(cdc[cdc$gender == "f", ])` do gênero feminino.

Cada uma dessas variáveis corresponde a uma questão que foi feita na pesquisa. Por exemplo, para `genhlth`, os respondentes foram indagados sobre sua saúde geral, respondendo good, very good, excellent e fair. A variável `exerany` indica se o respondente se exercitou no último mês (1) ou não (0). Da mesma forma, `hlthplan` indica se o respondente tem alguma forma de cobertura por plano de saúde (1) ou não (0). A variável `smoke100` indica se o respondente fumou pelo menos 100 cigarros ao longo da vida. As variáveis `height`, `weight`, `wtdesire`, `age` e `gender` registram a altura (em polegadas), o peso (em libras), o peso desejado (em libras), a idade (em anos) e o gênero, respectivamente.

Em tese, você poderia verificar toda a base de dados de só uma vez digitando seu nome no console, mas isso pode não ser muito sábio neste caso. Sabemos que `cdc` tem 20.000 linhas, portanto verificar o conjunto de dados inteiro significa inundar sua tela. Uma função bastante útil para dar uma rápida olhada no seu conjunto de dados, ver suas dimensões e os tipos de dados é a função `str`:

```{r}
str(cdc)
```

Note que o R chama as as variáveis categóricas de `factor` e a quantidade de categorias de `levels`. Você também poderá dar pequenas espiadas nos dados utilizando os comandos `head` (que mostra as primeiras linhas de dados). Vamos utilizar também a função `kable()`, do pacote `kableExtra`, a fim de deixar a tabela com um layout agradável:

```{r}
head(cdc) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

`tail()` (que mostra as últimas linhas de dados):

```{r}
tail(cdc) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

ou as técnicas de construção de subconjuntos que você aprenderá no decorrer do laboratório.

Por outro lado, se quisermos mostrar o banco de dados na saída do arquivo html como uma tabela estruturada, podemos usar a biblioteca `rmarkdown`:

```{r}
paged_table(cdc)
```

<br>

Podemos também estruturar a tabela de saída por meio da biblioteca `kableExtra`, mudando o nome das colunas da maneira que achar conveniente:

```{r}
kable(head(cdc, 10), col.names = c("Saúde", "Atividade Física", "Plano de Saúde", "Fumou nos últimos 100 dias?", "Altura", "Peso", "Peso desejado", "Idade", "Gênero")) %>% 
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

<br>

## Descrevendo Distribuições

### Histogramas

O questionário do BRFSS é um tesouro enorme de informações. Um primeiro passo útil em qualquer análise é destilar toda essa informação em algumas estatísticas sumárias e gráficos.

Vamos começar olhando alguns histogramas. Nós podemos criar um histograma da idade dos respondentes com o seguinte comando:

```{r}
cdc %>%
  ggplot(aes(x = age)) + 
  geom_histogram(col = "black", fill = "orange") + 
  labs(
    x = "idade",
    y = "contagem",
    title = "Histograma da idade"
  ) +
  theme(text = element_text(size = 18))
```

Esta função diz ao R para plotar a `age` no eixo-x. Além disso, a entrada `geom_histogram` (abreviação para geometric object) diz ao R o tipo de gráfico a ser plotado.

Outro comentário interessante se deve ao fato do R reportar suas análises no idioma inglês. Como você pode notar, no caso do histograma, o eixo-x é descrito de acordo com o nome originário do conjunto de dados, enquanto o eixo-y recebe a descrição *count* (número de observações para o intervalo correspondente). Caso você queira mudar os nomes apresentados nos eixos do gráfico plotado, basta indicar ao R o nome desejado.


Histogramas costumam ser uma boa maneira de enxergar a forma da distribuição de uma variável, mas esta forma pode variar dependendo do número de intervalos escolhido (ou a amplitude de cada intervalo) para representar cada barra do histograma. Você pode definir facilmente a amplitude de cada intervalo ao indicá-lo ao R por meio do argumento `binwidth`:

```{r}
cdc %>%
  ggplot(aes(x = age)) + 
  geom_histogram(col = "black", fill = "orange", binwidth = 1) + 
  labs(
    x = "idade",
    y = "contagem",
    title = "Histograma da idade"
  ) +
  theme(text = element_text(size = 18))

cdc %>%
  ggplot(aes(x = age)) + 
  geom_histogram(col = "black", fill = "orange", binwidth = 20) + 
  labs(
    x = "idade",
    y = "contagem",
    title = "Histograma da idade"
  ) +
  theme(text = element_text(size = 18))
```

É uma boa ideia explicitar em seu código todas as opções ao invés de aceitar as entradas padrões do R. Isso lhe permitirá a construção de gráficos mais informacionais e esteticamente mais agradáveis.

Além disso, podemos adicionar transparência ao gráfico por meio do argumento `alpha`, assim como também podemos escolher o número de classes através do argumento `bins` abaixo:

```{r}
cdc %>%
  ggplot(aes(x = age)) + 
  geom_histogram(col = "black", fill = "orange", alpha = .4, bins = 30) + 
  labs(
    x = "idade",
    y = "contagem",
    title = "Histograma da idade"
  ) +
  theme(text = element_text(size = 18))
```

Existem diversas possibilidades para alterar a estética dos seus gráficos e, para tal, nós o incentivamos a procurar informações à respeito dos comandos do R, assim como do pacote ggplot2. Por fim, é bastante comum que queiramos construir um histograma onde o eixo-y contenha uma medida de altura adequada, de tal modo que a área de cada bloco seja correspondente à frequência relativa do intervalo que representa a base do bloco, ao invés do número de observações. Neste caso, não podemos nos basear no formato do comando qplot, mas o pacote ggplot2 nos oferece alternativas interessantes e podemos obter esse gráfico com o comando abaixo:

```{r}
cdc %>%
  ggplot(aes(x = age)) + 
  geom_histogram(
    aes(y = after_stat(density)), 
    col = "black", 
    fill = "orange", 
    alpha = .4, 
    bins = 30
    ) + 
  labs(
    x = "idade",
    y = "contagem",
    title = "Histograma da idade"
  ) +
  theme(text = element_text(size = 18))
```

Em todos os casos acima, `aes` indica ao R quais as variáveis correspondentes a cada eixo, `geom_histogram` indica ao R a geometria do histograma (no caso, escolhemos a densidade para o eixo-y) e as demais entradas são bastante similares às que comentamos nos gráficos anteriores. O comando + indica ao R que ao gráfico serão adicionadas novas informações adiante. Poderíamos, inclusive, adicionar uma linha com a densidade estimada ao último gráfico com o comando abaixo:

```{r}
cdc %>%
  ggplot(aes(x = age)) + 
  geom_histogram(
    aes(y = after_stat(density)), 
    col = "black", 
    fill = "orange", 
    alpha = .4, 
    bins = 30
    ) + 
  geom_density(
    col = "red", 
    linewidth = 1
    ) +
  labs(
    x = "idade",
    y = "contagem",
    title = "Histograma da idade"
  ) +
  theme(text = element_text(size = 18))
```

### Estatísticas Descritivas

Como um exemplo simples, a função `summary` retorna um sumário numérico: mínimo, primeiro quartil, mediana, média, terceiro quartil e máximo. Para a variável `peso`do nosso conjunto de dados `cdc`, este sumário é dado por:

```{r}
cdc %>%
  select(weight) %>%
  summary()
```

Alternativamente, poderíamos ter a mesma saída acima com o seguinte comando:

```{r}
summary(cdc$weight)
```

> O operador %>% é chamado de operedor de direcionamento. Basicamente, ele pega a saída da linha corrente e a direciona à linha de código seguinte.

Você também pode criar a sua própria lista de estatísticas descritivas escolhendo aquelas que te interessam, assim como as variáveis que deseja visualizar usando a função `summarise`:

```{r}
summarise(
  cdc, 
  media_pe = mean(weight), 
  dp_pe = sd(weight), 
  media_alt = mean(height), 
  dp_alt = sd(height)
  ) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

ou calcular uma estatística descritiva individualmente com o comando

```{r}
mean(cdc$weight)
median(cdc$height)
```

Note que na função `summarise` nós criamos uma lista de quatro elementos. Os nomes desses elementos são definidos pelo usuário, por exemplo `mean_pe`, `dp_pe`, etc. e você pode alterá-los como quiser (apenas não utilize espaço entre seus nomes). Ao calcular estas estatísticas, o R também exige que você conheça as chamadas das funções. Algumas chamadas úteis para estatísticas descritivas numéricas únicas seguem abaixo com seu significado:

-   `mean` - calcula a média
-   `median` - calcula a mediana
-   `sd` - calcula o desvio padrão amostral
-   `var` - calcula a variância amostral
-   `IQR` - calcula a distância interquantil
-   `range` - calcula o mínimo e o máximo
-   `min` - calcula o mínimo
-   `max` - calcula o máximo

Uma outra funcionalidade bastante útil é você ser capaz de calcular estatísticas descritivas para várias categorias no seu banco de dados. Por exemplo, nós podemos calcular as estatísticas desejadas separadamente para os grupos masculino e feminino usando a função `group_by`:

```{r}
cdc %>%
  group_by(gender) %>%
  summarise(
    media_pe = mean(weight), 
    dp_pe = sd(weight), 
    media_al = mean(height), 
    dp_al = sd(height)
    ) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Aqui, primeiramente agrupamos os dados por gênero, e depois calculamos as estatísticas descritivas.

-   Exercício 2: Calcule a mediana e a distância interquantil da variável `peso`, separadamente, para pessoas que se exercitaram ou não no último mês.

```{r}
cdc %>%
  group_by(exerany) %>%
  summarise(
    median_pe = median(weight), 
    dq_peso = IQR(weight)
    ) %>%
  kable() %>%
     kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

### Tabelas

Ainda que faça sentido descrever uma variável quantitativa como `peso` em termos destas estatísticas, o que fazer com variáveis qualitativas? Nós podemos considerar a frequência da amostra ou a distribuição relativa de frequência. A função `table` faz isso por você contando o número de vezes que cada tipo de resposta é dada. Por exemplo, para ver o número de pessoas que fumaram 100 cigarros ao longo de sua vida, digite

```{r}
cdc %>%
  select(smoke100) %>%
  table()
```

ou então, verifique a distribuição da frequência relativa digitando

```{r}
cdc %>%
  select(smoke100) %>%
  table()/20000
```

Perceba como o R automaticamente divide todas as entradas na tabela por 20.000 no comando acima. Isso é similar a algo que observamos no último laboratório; quando multiplicamos ou dividimos um vetor por um número, o R aplica essa ação a todas as entradas dos vetores. Como vimos acima, isso também funciona para tabelas. 

A seguir, criamos um gráfico de barras para as entradas na tabela:



```{r}
cdc %>%
  select(smoke100, gender) %>%
  mutate(smoke100 = ifelse(smoke100 == 1, "Sim", "Não")) %>%
  ggplot(aes(x = smoke100, fill = gender)) + 
  geom_bar(position = "dodge", width = 0.5) + 
  labs(
    x = "Fumou pelo menos 100 cigarros?",
    y = "Número de indivíduos",
    title = "Distribuição dos Fumantes por Gênero"
  ) + 
  theme(text = element_text(size = 18))
```


-   Calcule a distribuição da frequência relativa para as variáveis `gender` e `genhlth`. Quantos homens compõem a amostra? Qual proporção da amostra diz estar com saúde excelente?

Para a variável `gender` temos, em relação ao total:

```{r}
cdc %>%
  select(gender) %>%
  table() %>%
  prop.table()
```

Já para a variável `genhlth`, temos:

```{r}
cdc %>%
  select(genhlth) %>%
  table() %>%
  prop.table()
```

O comando `table` pode também ser utilizado para criar tabelas de contingência. Por exemplo, para examinar quais participantes fumaram separadamente por gênero, podemos usar os comandos abaixo.

```{r}
cdc %>%
  select(gender, smoke100) %>%
  table()
```

<br>

a.  Qual percentual de fumantes são homens? Qual percentual de fumantes são mulheres?

Para responder essa pergunta, da forma como dispusemos os dados, precisamos determinar o percentual em relação ao total da coluna:

```{r}
cdc %>%
  select(gender, smoke100) %>%
  table() %>%
  prop.table(margin = 2)
```

Nesse caso, vemos que aproximadamente 53% dos fumantes são homens e aproximadamente 47% são mulheres. Poderíamos também estar interessados em determinar os percentuais em relação ao total geral de indivíduos na amostra:

```{r}
cdc %>%
  select(gender, smoke100) %>%
  table() %>%
  prop.table()
```

Poderíamos fazer o mesmo procedimento apenas com filtros no dataframe, sem usar a função ```table()```. Por exemplo, para determinar o percentual de fumantes que são mulheres, fazemos:

```{r}
nrow( cdc[cdc$smoke100 == 1 & cdc$gender == 'f', ] ) / nrow( cdc[cdc$smoke100 == 1, ] )
```

b.  Dentre os homens, qual o percentual dos que são fumantes? Dentre as mulheres, qual o percentual das que são fumantes?

Para responder a essa pergunta, da forma como dispusemos os dados, precisamos determinar o percentual em relação ao total da linha:

```{r}
cdc %>%
  select(gender, smoke100) %>%
  table() %>%
  prop.table(margin = 1)
```

Nesse caso, vemos que o percentual de homens que são fumantes é aproximandamente 52%, enquanto nas mulheres esse percentual é de aproximadamente 42%.

c.  Qual par de estatísticas é mais útil para determinar se é mais provável um homem ou uma mulher ser fumante? Justifique sua resposta.

Penso que, nesse caso, o melhor par de estatísticas para estimar se é mais provável um homem ou uma mulher ser fumante é aquele calculado no item 1, ou seja, dentre os fumantes, qual o percentual de homens e de mulheres.

-   **Indo um pouco além:** uma outra maneira de olhar para essas tabelas de contingência é olhar para os totais (e não percentuais) em cada linha ou coluna. Isso pode ser feito com o uso da função `margin.table()`, da seguinte forma:

1.  Somando sobre a linha:

```{r}
cdc %>%
  select(gender, smoke100) %>%
  table() %>%
  margin.table(margin = 1)
```

Nesse caso, a saída está nos retornando o número total de mulheres e de homens no conjunto de dados.

2.  Somando sobre a coluna:

```{r}
cdc %>%
  select(gender, smoke100) %>%
  table() %>%
  margin.table(margin = 2)
```


Já aqui, como a soma está sendo feita ao longo da coluna, a saída está nos fornecendo o total de fumantes e de não fumantes.

## Visualizando Relações 

### Entre duas variáveis quantitativas

No último laboratório nós visualizamos a relação entre duas variáveis numéricas usando gráficos de dispersão. Como um rápido lembrete, vamos criar mais um desses gráficos:

```{r}
cdc %>%
  ggplot(aes(x = height, y = weight)) + 
  geom_point(size = 1.5, color = "red") + 
  labs(
    title = "Peso versus altura"
  ) + 
  theme(text = element_text(size = 18))
```

Uma medida importante que nos dá informação de como duas variáveis numéricas estão relacionadas é a correlação. Podemos calcular a correlação entre duas variáveis numéricas por meio do comando `cor`. Abaixo calculamos a correlação entre as variáveis peso e altura:

```{r}
cor(cdc$weight, cdc$height)
```

- Com base no gráfico de dispersão e na medida de correlação, como você explica a relação entre essas variáveis?

Com base no baixo valor da correlação linear entre as duas variáveis ($\rho \approx 0,56$), concluímos que há uma correlação linear fraca entre elas.

### Entre duas variáveis qualitativas

Para criar um gráfico de barras segmentado nós podemos utilizar a seguinte opção.


```{r}
cdc %>%
  select(smoke100, gender) %>%
  mutate(smoke100 = ifelse(smoke100 == 1, "Sim", "Não")) %>%
  ggplot(aes(x = smoke100, fill = gender)) + 
  geom_bar(position = "dodge", width = 0.5) + 
  coord_flip() + 
  labs(
    x = "Fumou pelo menos 100 cigarros?",
    y = "Número de indivíduos",
    title = "Distribuição dos Fumantes por Gênero"
  ) + 
  theme(text = element_text(size = 18))
```


### Entre uma variável quantitativa e uma qualitativa

A finalidade de um boxplot é proporcionar um esboço de uma variável com o propósito de comparar as categorias existentes. Portanto, podemos, por exemplo, comparar as alturas de homens e mulheres com


```{r}
cdc %>%
  ggplot(aes(x = gender, y = height, fill = gender)) + 
  geom_boxplot(width = 0.4) + 
  labs(
    x = "",
    title = "Altura em função do gênero"
  ) +
  theme_void() + 
  theme(text = element_text(size = 20))
```

Há uma nova notação para a geometria aqui. Nós pedimos ao R para plotar os boxplots da altura em relação aos gêneros masculino e feminino que estão descritos no banco de dados.

Vamos considerar uma nova variável que não aparece diretamente neste conjunto de dados: o Índice de Massa Corporal (IMC) (<https://pt.wikipedia.org/wiki/%C3%8Dndice_de_massa_corporal>).

O IMC é uma razão entre peso e altura calculado segundo a fórmula:

$$ IMC = \dfrac{peso}{altura^2} $$ 

Como nossos dados não estão nas unidades métricas (quilogramas e metros) e sim nas unidades imperiais (libras e polegadas) multiplicamos a primeira fórmula por 703 (que é o valor aproximado de conversão das unidades métricas para imperiais), obtendo a fórmula

$$ IMC = \dfrac{peso}{altura^2}*703 $$

Agora, podemos usar a função `mutate` para adicionar uma nova variável, relativa ao IMC, ao conjunto de dados `cdc`:

```{r}
cdc = mutate(cdc, imc = (weight/height^2)*703)
```

Perceba que a primeira linha acima representa uma simples aritmética, mas é aplicada para todos os 20.000 elementos do conjunto de dados `cdc`. Ou seja, para cada um dos 20.000 participantes, pegamos seu peso, dividimos pelo quadrado de sua altura e multiplicamos por 703. O resultado são 20.000 valores de IMC, um para cada respondente. Essa é uma das razões pela qual gostamos do R: ele nos permite realizar cálculos como esse utilizando expressões bem simples.

Agora nós podemos utilizar esta nova variável em nossa análise. Por exemplo, vamos criar uma sequência de boxplots da variável `imc` à partir das categorias da variável `saude`.


```{r}
cdc %>%
  ggplot(aes(x = genhlth, y = imc, fill = genhlth)) + 
  geom_boxplot(size = 0.6) + 
  theme_void() + 
  scale_fill_manual(values = c("green", "skyblue", "orange", "yellow", "red")) + 
  theme(text = element_text(size = 20))
```

-   Essa figura nos mostra que, quanto pior o estado de saúde relatado da pessoa, maior é o seu IMC mediano.

-   Escolha outra variável qualitativa do banco de dados e verifique como ela se relaciona ao IMC. Liste a variável que você escolheu, explique por que você pensou que ela poderia ter alguma relação com o IMC, construa uma sequência de boxplots à partir das categorias da variável e indique o que o gráfico parece sugerir.

```{r}
cdc %>%
  ggplot(aes(x = gender, y = imc, fill = gender)) + 
  geom_boxplot(size = 0.6, width = 0.4) + 
  theme_void() + 
  theme(text = element_text(size = 20))
```


Esperamos que o IMC médio (ou mediano) varie entre os gêneros, por isso escolhemos essa variável para analisar o comportamento dessa medida nos dois grupos disponíveis. Conforme vemos no boxplot acima, os homens possuem um IMC maior. Contudo, as mulheres possuem outliers mais acentuados.

## Subconjuntos

É bastante comum agruparmos em subconjuntos elementos individuais do banco de dados que possuam características específicas. Nós podemos fazer isso facilmente por meio da função `filter` e uma série de operadores lógicos. Os operadores lógicos mais comuns na análise de dados são

-   `==` - significa "igual a"
-   `!=` - significa "diferente de"
-   `>` or `<` - significa "maior que" ou "menor que"
-   `>=` or `<=` - siginifica "maior ou igual que" ou "menor ou igual que"

Usando esses operadores, nós podemos criar um subconjunto do banco de dados `cdc` relativo apenas aos homens e, então, salvar esta filtragem em um novo conjunto de dados chamado `homens`:

```{r}
men = filter(cdc, gender == "m")
```

Aqui nós criamos um novo objeto, chamado `men`. Nós podemos dar uma olhada neste objeto clicando sobre o banco de dados `homens` que aparece em seu ambiente de traballho (Environment), ou podemos usar o comando `head` para dar uma espiada nas suas primeiras linhas:

```{r}
head(men) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Este novo conjunto de dados contém as mesmas variáveis de antes, apenas com um número menor de linhas. Nós também poderíamos dizer ao R para manter algumas variáveis específicas usando a função `select` que foi introduzida anteriormente, mas isto não é relevante no momento, uma vez que iremos focar na criação de subconjuntos do banco de dados.


```{r}
men2 = cdc %>%
  subset(gender == "m", select = c(gender, genhlth, age))
```

Você poderá utilizar diversas dessas condições conjuntamente aos condicionadores `&` and `|`. O condicionador `&` corresponde à intersecção. A grosso modo, podemos dizer que `&` é equivalente a `e`. Nos comandos abaixo, agrupamos em um banco de dados os indivíduos que são homens e possuem mais de trinta anos:

```{r}
homens_e_30mais = filter(cdc, gender == "m" & age > 30)
```

Já o condicionador `|` corresponde à união e, podemos dizer, que é equivalente a `ou`. O comando abaixo agrupa os indivíduos do conjunto de dados que são homens ou possuam mais de 30 anos:

```{r}
homens_ou_30mais = filter(cdc, gender == "m" | age > 30)
```

À princípio, você pode usar esses condicionadores na quantidade e da maneira que decidir para formar subconjuntos. Se estes agrupamentos tem interpretações práticas é uma outra questão

-   Crie um novo objeto `menos23_fumante` relativo àqueles que possuem menos de 23 anos e já fumaram 100 cigarros em seu tempo de vida. Escreva o comando que você utilizou para criar este novo objeto e apresente o número de casos que atendem a esse critério.

```{r}
menos23_fumante = filter(cdc, age < 23 & smoke100 == 1)
```

Vemos então que `r nrow(menos23_fumante)` indivíduos do nosso banco de dados atendem à condição de ter menos que 23 anos e já ter fumado pelos menos 100 cigarros ao longo da vida.

## Recapitulando

A esta altura, fizemos uma boa primeira exposição sobre a análise das informações contidas no questionário BRFSS. Nós descobrimos uma associação interessante entre fumo e gênero, e nós podemos comentar algo a respeito da relação entre a avaliação de saúde em geral dada pelas pessoas e seu próprio IMC. Nós também nos apropriamos de ferramentas computacionais essenciais -- estatísticas descritivas, subconjuntos e gráficos -- que nos servirão bem ao longo deste curso.

## Por sua conta

1.  Crie um gráfico de dispersão da variável peso em relação ao peso desejado. Descreva a relação entre essas duas variáveis.


```{r}
cdc %>%
  ggplot(aes(x = wtdesire, y = weight)) + 
  geom_point(size = 1.8, color = "orange") +
  labs(
    title = "Peso desejado versus peso real",
    x = "peso real",
    y = "peso desejado"
  ) +
  theme(text = element_text(size = 18))

cor(cdc$wtdesire, cdc$weight)
```

O gráfico de dispersão mostrado acima mostra uma relação praticamente linear entre as variáveis `weight` e `wtdesire`. Este fato é corroborado pelo coeficiente de correlação linear entre as variáveis, que foi de aproximadamente 0.8.

2.  Vamos considerar uma nova variável: a diferença entre o peso desejado (`wtdesire`) e o peso atual (`weight`). Crie esta nova variável subtraindo as duas colunas na base de dados e atribuindo-as a um novo objeto chamado `pdif`.

```{r}
pdif = cdc$wtdesire - cdc$weight
```

3.  Que tipo de dados estão contidos na variável `pdif`? Se uma observação de pdif é 0, o que isso implica em relação ao peso atual e desejado de uma pessoa? E se o valor de pdif for positivo ou negativo?

```{r}
typeof(pdif)

typeof(cdc$weight)

typeof(cdc$wtdesire)
```

Como podemos ver na saída dos comandos acima, as variáveis `weight` e `wtdesire` são ambas do tipo `integer`, de modo que `pdif`, que é a diferença entre aquelas duas, é também do tipo inteiro. Vemos então que tanto o peso como o peso desejado foram registrados em quilos no nosso banco de dados, sem a parte fracionária.


Vemos ainda que, se `pdif` é zero, a pessoa já acredita que está em seu peso ideal, desejado. Se essa quantidade é positiva, ela acredita que seu peso precisa aumentar e, se é negativa, ela acredita que precisa perder peso.

4.  Descreva a distribuição de `pdif` em termos de sua posição central, forma e variação, incluindo qualquer gráfico que você usar. O que isso nos diz sobre como as pessoas se sentem a respeito do seu peso atual?


```{r}
cdc = mutate(cdc, pdif = wtdesire - weight)
```

```{r}
cdc %>%
  select(pdif) %>%
  summary()
```


```{r}
cdc %>%
  ggplot(aes(x = pdif)) +
  geom_histogram(aes(y = after_stat(density)), 
                 fill = "orange", bins = 50, alpha = 0.8, color = "black") +
  labs(
    x = "P_dif", 
    y = "Densidade", 
    title = "Histograma da diferença entre o peso desejado e o atual"
  ) + 
  theme(text = element_text(size = 18))
```

Com este resumo dos dados da variável `pdif` que fizemos logo acima, percebemos que, em média, os participantes acreditam que estão próximos de seu peso ideal, com cerca de 6 quilos acima. Além disso, a partir do histograma e do boxplot gerados, podemos notar também que a distribuição das diferenças entre os pesos ideal e real dos participantes do estudo é praticamente simétrica. Contudo, podemos notar também que existem mais pessoas acreditando que estão acima do peso ideal do que abaixo dele.


5.  Utilizando estatísticas numéricas e uma sequência de boxplots, determine se homens tendem a ver seu peso diferentemente das mulheres.

```{r}
cdc %>%
  group_by(gender) %>%
  summarize(
    media_pdif = mean(pdif), 
    sd_pdif = sd(pdif), 
    mediana_pdif = median(pdif), 
    dq_pdif = IQR(pdif)
    ) %>%
    kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )

cdc %>%
  ggplot(aes(x = gender, y = pdif, fill = gender)) +
  geom_boxplot(width = 0.4) + 
  theme_void() + 
  theme(text = element_text(size = 20))
```

Conforme vemos nas estatísticas calculadas acima, bem como nos boxplots, dentre os participantes do estudo, as mulheres tendem a achar que estão mais acima do peso do que os homens pensam sobre eles mesmos.

6.  Agora chegou a hora de usar a criatividade. Encontre a média e o desvio padrão de peso e determine qual a proporção de pesos que estão a um desvio padrão da média. E a dois desvios padrões da média?

Para responder a essas perguntas, basta calcularmos, dentro do nosso dataframe, a proporção de elementos que satisfazem as seguintes condições

$$ |P-\bar{P}| < sd(P)  $$

$$ |P-\bar{P}| < 2*sd(P)  $$

```{r}
nrow(filter(cdc, abs(weight - mean(weight)) < sd(weight)))/nrow(cdc)

nrow(filter(cdc, abs(weight - mean(weight)) < 2*sd(weight)))/nrow(cdc)
```

Como podemos ver, aproximadamente 70% dos valores dos pesos dos entrevistados estão dentro de 1 desvio padrão da média, ao passo que aproxidamente 95% dos valores estão dentro de dois desvios padrões de distância da média. Vemos, portanto, que o peso dos indivíduos entrevistados seguem uma distribuição aproximadamente normal. Isto pode ser corroborado com um histograma para essa variável:


```{r}
cdc %>%
  ggplot(aes(x = weight)) +
  geom_histogram(
    aes(y = after_stat(density)), 
    fill = "blue",
    alpha = 0.5,
    col = "black"
    ) + 
  labs(
    x = "Peso", 
    y = "Densidade",
    title = "Histograma para os pesos dos participantes do estudo"
    ) + 
  theme(text = element_text(size = 18))
```



# Lab03: Probabilidade: Mãos Quentes (Hot Hands)


## Conteúdos abordados neste laboratório

* Probabilidade
* Eventos independentes
* Simulações de eventos independentes no R

## Mãos Quentes (Hot Hands)

Jogadores de basquete que pontuam várias vezes seguidas costumam ser descritos como tendo as *mãos quentes*. Fãs e jogadores acreditam há muito tempo no fenômeno das mãos quentes, que refuta o pressuposto de que cada lance é independente do próximo. Contudo, um artigo de 1985 escrito por Gilovich, Vallone e Tversky coletou evidências que contradizem essa crença e mostrou que lances sucessivos são eventos independentes. Este artigo iniciou uma grande controvérsia que continua até hoje, como você pode verificar se procurar por *hot hand basketball* no Google.

Não temos a expectativa de resolver esta controvérsia hoje. Entretanto, neste laboratório nós aplicaremos um procedimento para responder a questões como essa. Os objetivos deste laboratório são (1) **refletir sobre o efeito de eventos dependentes e independentes**, (2) **aprender como simular sequências de lances no R**, e (3) **comparar a simulação com os dados efetivos para determinar se o fenômeno das mãos quentes parece ser real**.


## Começando

Nossa investigação terá como foco a performance de um jogador: Kobe Bryant do Los Angeles Lakers. Sua performance contra o Orlando Magic nas finais de 2009 da NBA lhe deram o título de Jogador Mais Valioso (ou, em inglês, *Most Valuable Player*) e vários espectadores comentaram como ele parecia demonstrar a característica de mãos quentes. Vamos carregar alguns dados desses jogos que iremos utilizar durante este laboratório.


```{r}
load(file = "hot_hand.Rdata")
```


Você deve ver dois objetos na aba Environment: ```kobe_basket``` e ```calc_streak```:

* ```kobe_basket```: um conjunto de dados de 133 observações e 6 variávies, onde cada linha registra um arremesso feito por Kobe Bryant. A variável `basket` indica se o arremesso foi um acerto (H) ou um erro (M).

* ```calc_streak```: uma função customizada que irá nos ajudar a calcular comprimentos de sequências de acertos (mais sobre isso à frente).


```{r}
names(kobe_basket)
head(kobe_basket) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
  )
```


Apenas olhando para a sequência de acertos e erros pode ser difícil de auferir se é provável que Kobe estava arremessando com as mãos quentes. Uma possível maneira de abordarmos este problema é supormos que arremessadores com as mãos quentes tendem a conseguir uma longa sequência de acertos. Para este laboratório, definiremos o comprimento de uma sequência de acertos como o *número de cestas consecutivas até acontecer um erro*.

Por exemplo, no Jogo 1, Kobe teve a seguinte sequência de acertos e erros de suas nove tentativas de arremessos no primeiro quarto:

<center>
**H M** | **M** | **H H M** | **M** | **M** | **M**
</center>

Para verificar esta informação, use o seguinte comando:

```{r}
kobe_basket%>%
  filter(game == 1, quarter == 1) %>%
  select(shot)
```

Dentre as nove tentativas de arremesso existem seis sequências, que são separadas por um “|” acima. Seus comprimentos são um, zero, dois, zero, zero, zero (em ordem de ocorrência). Vemos então que em uma sequência de comprimento 1 existe 1 acerto e 1 erro, ao passo que na sequência de comprimento 0 existe 0 acerto e 1 erro. Uma sequência de comprimento 2, por sua vez, contêm 2 acertos e 1 erro. Portanto, uma sequência de comprimento L contêm L acertos e 1 erro.

Contar os comprimentos de todos os 133 arremessos manualmente seria extremamente tedioso, então iremos utilizar a função ```calc_streak``` para realizar este trabalho para nós. Os resultados serão armazenados em um conjunto de dados chamado ```kobe_streak``` como a variável ```length``` (comprimento em inglês).


```{r}
kobe_streak = kobe_basket %>%
  select(shot) %>%
  calc_streak()
```


Nós podemos dar uma olhada na distribuição desses comprimentos com o comando abaixo.


```{r}
kobe_streak %>%
  ggplot(aes(x = length)) +
  geom_histogram(binwidth = 1, col = "black", fill = "orange") + 
  labs(
    title = "Tamanho das sequências de arremesso de Kobe",
    y = "N"
    ) +
  theme(text = element_text(size=18))
```


```{r}
summary(kobe_streak)

table(kobe_streak)
```

Conforme podemos ver na saída de código acima, o comprimento típico das sequências de Kobe foi zero. Além disso, podemos ver também que a mediana dos comprimentos das sequências é também zero, enquanto a média é um número menor que 1.


## Ao que comparar

Nós mostramos que Kobe teve algumas sequências longas de arremesso, mas elas são longas o suficiente para apoiar a crença de que ele tinha mãos quentes? Com o que podemos compará-las?

Para responder a essa pergunta, vamos retornar ao conceito de *independência*. Dois eventos são independentes se o resultado de um evento não afeta o resultado do outro. Se cada arremesso do jogador for um evento independente, acertar ou errar o primeiro arremesso não afetará a probabilidade de ele converter ou errar o segundo arremesso.

Um arremessador com as mãos quentes terá arremessos que *não* são independentes um do outro. Mais especificamente, se o arremessador converte seu primeiro arremesso, o modelo acerca das mãos quentes afirma que ele terá uma probabilidade *maior* de converter seu segundo arremesso.

Vamos supor por um momento que o modelo das mãos quentes é válido para Kobe. Durante sua carreira, o percentual de vezes que Kobe acertou uma cesta (ou seja, seu percentual de arremessos convertidos) é de cerca de 45%, ou, em notação de probabilidade,

<center>
**P(arremesso 1 = H) = 0.45**
</center>

Se ele converte o primeiro arremesso e tem as mãos quentes (arremessos não independentes), então a probabilidade de ele converter seu segundo arremesso deveria aumentar para, digamos, 60%,

<center>
**P(arremesso 2 = H | arremesso 1 = H) = 0.60**
</center>

Como um resultado do aumento da probabilidade, seria esperado que Kobe obtivesse sequências mais longas. Compare com a perspectiva cética de que Kobe *não* tenha as mãos quentes, ou seja, que cada arremesso é independente do anterior. Se ele acerta seu primeiro arremesso, a probabilidade de ele acertar o segundo continua sendo 0.45.

<center>
**P(arremesso 2 = H | arremesso 1 = H) = 0.45**
</center>

Em outras palavras, converter o primeiro arremesso não afeta de maneira alguma a probabilidade de ele converter o segundo arremesso. Se os arremessos de Kobe forem independentes, então ele teria a mesma probabilidade de acertar cada arremesso independentemente de seus arremessos anteriores: 45%.

Agora que reformulamos a situação em termos de arremessos independentes, vamos retornar à questão: como podemos saber se as sequências de arremessos de Kobe são longas o suficiente para indicar que ele tem mãos quentes? Podemos comparar o tamanho de suas sequências a alguém que não tem as mãos quentes: um arremessador independente.


## Simulações no R

Embora não tenhamos dados de um “arremessador independente”, esse tipo de dado é muito fácil de ser simulado no R. Numa simulação, você define as regras básicas de um processo aleatório e então o computador utiliza números aleatórios para gerar um resultado fiel a essas regras. Como um exemplo simples, vamos simular o lançamento de uma moeda honesta onde ```K``` simboliza cara e ```C``` simboliza coroa:

```{r}
face_moeda = c("K", "C")
sample(face_moeda, size = 1, replace = T)
```

Primeiramente registramos os possíveis resultados no vetor ```face_moeda```. O comando ```sample``` realiza uma amostra do experimento ao selecionar aleatoriamente um dos valores ```K``` ou ```C```. O vetor ```face_moeda``` pode ser entendido como um chapéu com duas tiras de papel dentro dele: numa tira está escrito ```K``` e na outra ```C```. A função ```sample``` sorteia uma tira de dentro do chapéu e revela se ela é cara ou coroa.

Execute o segundo comando listado acima várias vezes. Da mesma maneira que quando jogamos uma moeda, algumas vezes você obterá cara, algumas vezes você obterá coroa, mas a longo prazo você esperaria obter um número mais ou menos igual de cada possível resultado.

Se você quisesse simular o lançamento de uma moeda honesta 100 vezes, você poderia rodar a função 100 vezes ou, de forma mais simples, ajustar o argumento ```size``` (tamanho), que regula quantas amostras retirar. O argumento ```replace``` indica se há (TRUE) ou não (FALSE) reposição dos possíveis valores. Voltando à analogia do chapéu, TRUE indica que nós recolocamos a tira de papel de volta no chapéu antes de retirar as amostras seguintes. Salve o vetor resultante de caras e coroas num novo objeto denominado sim_moeda_honesta.


```{r}
sim_moeda_honesta = sample(face_moeda, 100, replace = T)

sim_moeda_honesta
```

Para visualizar os resultados desta simulação, digite o nome do objeto e então use o comando table pra contar o número de caras e coroas.

```{r}
table(sim_moeda_honesta)
```

Uma vez que há apenas dois elementos no vetor ```face_moeda```, a probabilidade de que um lançamento dê o resultado cara é 0,5. Digamos que estamos tentando simular uma moeda viciada, onde a probabilidade de sair cara é 20%. Podemos ajustar a amostra adicionando um argumento denominado ```prob```, que fornece um vetor com as respectivas probabilidades.


```{r}
sim_moeda_viciada = sample(face_moeda, size = 100, replace = T, prob = c(0.2, 0.8))
```

```prob = c(0.2, 0.8)``` indica que, para os dois elementos no vetor ```face_moeda```, nós queremos selecionar o primeiro (cara) com probabilidade 0,2, e o segundo (coroa), com probabilidade 0,8. Outra maneira de pensar sobre esse cenário é imaginar o espaço amostral como um saco contendo 10 fichas, sendo 2 marcadas como “cara” e 8 como “coroa”. Portanto, a cada seleção, a probabilidade de retirar uma ficha escrito “cara” é 20%, e “coroa” é 80%.

> **Uma nota sobre sementes:** Especificar uma semente irá fazer com que o R obtenha a mesma amostra cada vez que você aperta o botão *Knit*. Isso garante a reprodutibilidade do seu trabalho, uma vez que os seus resultados serão os mesmos cada vez que você compilar os seus comandos. Você pode especificar uma semente com o comando abaixo:

```{r}
set.seed(123) #Podemos usar qualquer valor como semente, desde que 
#utilizemos sempre o mesmo ao longo das nossas simulações.
```


```{r}
set.seed(123)

sim_moeda_viciada_reprod = sample(face_moeda, 100, replace = T, prob = c(0.2,0.8))

sim_moeda_viciada_reprod

table(sim_moeda_viciada_reprod)
```

Num certo sentido, nós reduzimos o tamanho da tira de papel que diz “cara”, tornando-o menos provável de ser escolhido, e nós aumentamos o tamanho da tira de papel que diz “coroa”, tornando-o mais provável de ser retirado. Quando simulamos a moeda honesta, ambas as tiras de papel tinham o mesmo tamanho. Isso acontece de maneira padrão se você não fornecer o argumento ```prob```; todos os elementos no vetor ```face_moeda``` terão igual probabilidade de serem escolhidos.


## Simulando o arremessador independente

Para simular um jogador de basquete que arremessa de forma independente, utilizamos o mesmo mecanismo que empregamos para simular o lançamento de uma moeda. Para simular um único arremesso de um arremessador independente, com um percentual de acerto de 50%, digitamos


```{r}
arremesso = c("H", "M")
sim_cesta = sample(arremesso, 1, replace = T)
```

Para fazermos uma comparação válida entre Kobe e nosso arremessador independente simulado, precisamos alinhar tanto seus percentuais de arremesso quanto seus números de arremessos tentados.

Considerando os 133 arremessos de Kobe nas finais de 2009 da NBA, bem como seu percentual histório de acertos, que era de 45%, podemos simular como seria sua versão independente da seguinte forma:


```{r}
set.seed(123)
sim_cesta = sample(arremesso, size = 133, replace = T, prob = c(0.45, 0.55))
```

Observe que nomeamos o novo vetor como ```sim_cesta```, com o mesmo nome que demos ao vetor anterior correspondente a um percentual de arremesso de 50%. Nessa situação, o R sobrescreve o objeto antigo com o novo, portanto sempre se certifique que você não precisa da informação no vetor antigo antes de atribuir um novo objeto ao seu nome.

Com os resultados da simulação salvos como `sim_cesta`, temos os dados necessários para comparar Kobe ao nosso arremessador independente. Podemos visualizar os dados de Kobe em conjunto com os nossos dados simulados.

Ambos os conjuntos de dados representam o resultado de 133 tentativas de arremessos, cada uma com o mesmo percentual de acerto de 45%. Sabemos que nossos dados simulados são de um arremessador que arremessa de forma independente. Quer dizer, sabemos que o arremessador simulado não tem as mãos quentes.


## Por sua conta

1. Utilizando a função ```calc_streak```, calcule os comprimentos  das sequências de arremessos convertidos de ```sim_cesta``` e salve os resultados em um conjunto de dados chamado ```sim_streak```. Note que ```sim_streak``` é apenas um vetor e não uma variável de um conjunto de dados como o que utilizamos para calcular as sequências de Kobe. Desse modo, não é preciso selecionar a variável dentro de um conjunto de dados, bastando apenas aplicar a função ao vetor.


```{r}
sim_streak = calc_streak(sim_cesta)
```

2. Descreva a distribuição das sequências de arremessos. Qual é o comprimento de sequência típico para o arremessador independente simulado com um percentual de arremesso de 45%? Qual o comprimento da sequência mais longa de cestas em 133 arremessos? Não esqueça de incluir um gráfico à sua resposta.

Para começar, vamos ver um resumo estatístico das sequências de Kobe e do arremessador independente:


```{r}
summary(kobe_streak)

summary(sim_streak)
```

Vemos então que o tamanho máximo de uma sequência de Kobe foi igual a 4, ao passo que o arremessador independente alcançou um máximo de 7. As medianas são iguais e as médias muito parecidas.

Podemos ainda executar o comando ```table```, combinado com o comando ```prop.table()```, a fim de verificar, em cada conjunto de dados, o tamanho de sequência que mais ocorre:

```{r}
prop.table(table(kobe_streak))

prop.table(table(sim_streak))
```
Vemos, portanto, que as sequências ocorrem com frequências muito parecidas nos dois conjuntos de dados. Por exemplo, aproximadamente 51% das sequências de Kobe naquela final de temporada teve comprimento zero. No caso do simulador independente, esse percentual foi perto de 54%. Já as sequências de tamanho 2 ocorreram com frequência de aproximadamente 8% em ambos os casos. Por meio dessa análise, podemos concluir que os dois arremessadores são compatíveis.


Por fim, vamos comparar os histogramas para os comprimentos dos arremessos de Kobe e do arremessador independente:


```{r}
hist_kobe = ggplot(kobe_streak, aes(x = length)) +
  geom_histogram(col = "black", fill = "green", binwidth = 1) +
  labs(
    x = "Comprimento",
    y = "N",
    title = "Sequências de Kobe"
  ) +
  theme(text = element_text(size=18))

hist_sim = ggplot(sim_streak, aes(x = length)) +
  geom_histogram(col = "black", fill = "orange", binwidth = 1) +
  labs(
    x = "Comprimento",
    y = "",
    title = "Sequências simuladas"
  ) +
  theme(text = element_text(size=18))

cowplot::plot_grid(hist_kobe, hist_sim, labels = "AUTO")
```


# Lab04: Distribuições Amostrais


Neste laboratório, investigaremos os meios pelos quais as estatísticas de uma amostra aleatória de dados podem servir como estimativas pontuais de parâmetros populacionais. Estamos interessados em formular uma distribuição amostral de nossa estimativa para aprender sobre as propriedades da estimativa, como sua distribuição.


## Conteúdos abordados neste laboratório

* Amostragem no R
* Distribuição amostral da média
* Distribuição normal
* Teorema do Limite Central
* Histogramas
* Box plots

> **Especificando uma semente:** Nós iremos tomar amostras aleatórias e gerar algumas distribuições amostrais neste laboratório. Desse modo, você deverá especificar uma semente logo no início de seu relatório. Caso tenha dúvidas sobre como definir esta semente, retorne ao laboratório anterior onde explicamos este conceito.



```{r}
set.seed(123)
```


## Os dados


Vamos analisar dados do setor imobiliário da cidade de Ames, no estado de Iowa, Estados Unidos. Os detalhes de cada transação imobiliária na cidade de Ames são registrados pelo escritório da Secretaria Municipal da Receita da cidade. Nosso foco particular para este laboratório será todas as vendas de casa em Ames entre 2006 e 2010. Essa coleção representa nossa população de interesse. Neste laboratório queremos aprender sobre essas vendas de casas retirando pequenas amostras da população completa. Vamos importar os dados.


```{r}
load("ames.rda")
names(ames)
```


Como você pode observar, o banco de dados está em sua língua originária, inglês, e existe uma quantidade consideravelmente grande de variáveis. Para este laboratório, restringiremos nossa atenção para somente duas variáveis: a área habitável da casa acima do nível do solo em pés quadrados (```area```) e o preço da venda (```price```) em dólares.

Nós podemos explorar a distribuição da área das casas em nossa população de vendas de casas calculando algumas estatísticas sumárias e criando um histograma. Vamos iniciar criando uma visualização por meio do histograma:


```{r}
ames %>%
  ggplot(aes(x = area)) + 
  geom_histogram(fill = "orange", col = "black", binwidth = 250) + 
  labs(
    x = "Area",
    y = "N",
    title = "Histograma para as áreas das casas em Ames, Iowa"
  ) + 
  theme(text = element_text(size = 18))
```


Vamos obter, também, algumas medidas descritivas. Observe que podemos fazer isso por meio da função `summarise`. O número de estatísticas a serem calculadas fica a nosso critério. Algumas das funções abaixo já foram discutidas no primeiro laboratório (como `mean`, `median`, `sd`, `IQR`, `min`, e `max`). A função `quantile` aparece pela primeira vez em nossos laboratórios, correspondendo ao quantil especificado da distribuição de interesse. Por exemplo, a expressão `quantile(x, 0.25)` irá nos revelar o valor que acumula 25% (Q1) da distribuição da variável `X`. Conforme pode ser acompanhado em qualquer livro-texto de estatística básica, esses valores são úteis na descrição da distribuição dos dados: como exemplo, poderíamos estar interessados na “região central que acumula 50% das casas com área dada em pés quadrados”. Na saída abaixo, usamos também a função `kable`, do pacote `kableExtra`, para apresentar a saída da função `summarise` na forma de uma tabela:


```{r}
n = nrow(ames)
ames %>%
  summarise(
    mu = mean(area), 
    pop_med = median(area),
    sigma = ((n-1)/n)*sd(area), 
    pop_iqr = IQR(area),
    pop_min = min(area), pop_max = max(area),
    pop_q1 = quantile(area, 0.25),# primeiro quartil, 25º percentil
    pop_q3 = quantile(area, 0.75) # terceiro quartil, 75º percentil
    ) %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
  )
```


* **Exercício 1**: Descreva a distribuição desta população usando visualizações e estatísticas descritivas. Você não precisa usar todas as estatísticas descritivas existentes, mas deve decidir quais delas são relevantes baseando-se na forma da distribuição. Não esqueça de incluir os gráficos e saídas das estatísticas calculadas no seu relatório juntamente com a sua narrativa.


```{r}
ames %>%
  select(area) %>%
  filter(abs(area - mean(area)) < ((n-1)/n)*sd(area)) %>%
  nrow()/nrow(ames)
```

Como podemos notar a partir do histograma plotado e da saída do código logo acima, assim como através das estatísticas descritivas selecionadas na função `summarise`, a distribuição das áreas das habitações do nosso conjunto de dados é aproximadamente normal, porém, com uma leve assimetria à direita, devido aos poucos imóveis que possuem área muito maior que os demais (*outliers*). Isso pode ser reforçado pela visualização de um boxplot:

```{r}
ames %>%
  ggplot(aes(x = "", y = area)) + 
  geom_boxplot(width = 0.2, fill = "orange", outlier.color = "red") + 
  labs(
    title = "Boxplot para as áreas das casas em Ames, Iowa",
    x = "Area"
  ) + 
  theme_void() +
  theme(text = element_text(size = 18))
```


## A distribuição Amostral Desconhecida

Neste laboratório nós temos acesso à população inteira, mas isso raramente acontece na vida real. Reunir informação sobre uma população inteira costuma ser muito custoso ou impossível. Por essa razão, frequentemente retiramos uma amostra da população e a utilizamos para compreender propriedades da população.

Se estivermos interessados em estimar a área habitável média na cidade de Ames com base numa amostra, podemos utilizar o seguinte comando para sondar a população.

```{r}
set.seed(123)
amostra1 = slice_sample(ames, n = 50, replace = T)
```


Esse comando retira uma amostra aleatória simples de tamanho 50 do dataframe `ames`, que é atribuída à variável `amostra1`. É como se fossemos ao banco de dados da Secretaria Municipal da Fazenda e retirássemos os arquivos de 50 vendas de casas aleatoriamente. Trabalhar com esses 50 arquivos seria consideravelmente mais simples do que lidar com todas as 2930 vendas de casas.

* **Exercício 2**: Descreva a distribuição desta amostra. Como ela se compara à distribuição da população? Dica A função `slice_sample` retira uma amostra das observações (i.e. linhas) no banco de dados. Você pode utilizar os mesmos nomes para as variáveis do banco de dados. Os códigos utilizados no exercício anterior podem ser muito úteis para visualizar e descrever a distribuição, mas tenha cuidado ao nomear as estatísticas uma vez que `mu` e `sigma` são parâmetros populacionais já definidos e o que você tem é uma amostra e, consequentemente, estatísticas amostrais. Você pode nomear à sua escolha as estatísticas calculadas, sendo muito útil indicar no nome atribuído que seus valores são oriundos de uma amostra.

Se estamos interessados em estimar a área habitável média nas casas da cidade de Ames utilizando esta amostra, nosso melhor palpite é a média da amostra.

```{r}
summarise(amostra1, x_bar = mean(area))
```

Dependendo de quais foram as 50 casas que foram sorteadas, sua estimativa pode estar um pouco acima ou abaixo da média populacional verdadeira de 1499,69 pés quadrados. De maneira geral, mesmo assim, a média da amostra costuma ser uma estimativa muito boa da média da área habitável, e nós a obtemos por meio de uma amostra de menos de 3% da população.


Não é surpreendente que, a cada vez que retiramos uma nova amostra aleatória, obtemos uma média amostral diferente. É útil ter uma ideia de quanta variabilidade podemos esperar quando estimamos a média populacional desta maneira. A distribuição das médias amostrais, denominada de *distribuição amostral*, pode nos ajudar a compreeder essa variabilidade. Neste laboratório, uma vez que temos acesso à população, podemos elaborar a distribuição amostral para a média amostral repetindo os passos acima várias vezes. Agora iremos gerar 2000 amostras e calcularemos a média amostral de cada uma delas. Note que utilizamos o argumento `replace = TRUE` pelo simples fato de que amostras aleatórias simples são obtidas da distribuição original para cada réplica.


```{r}
set.seed(123)
amostra50 = rdply(2000, slice_sample(ames, n = 50, replace = T), .id = "id_sample")
```

para determinar as médias de cada uma das 2000 amostras de 50 elementos, utilizamos as funções da biblioteca `dplyr`, além do operador `%>%`:

```{r}
medias_amostra50 = amostra50 %>%
  group_by(id_sample) %>%
  summarise(x_bar = mean(area))
```


## Interlúdio: A função `rdply`

Na seção anterior, utilizamos a função `rdply`, do pacote `plyr`, para gerar `L = 2000` amostras de tamanho `n = 50` do nosso conjunto de dados `ames`. Para tanto, continuamos a utilizar a função `slice_sample`, da biblioteca `dplyr`. Contudo, como nesse caso não precisávemos apenas de uma amostra, mas de 2000, selecionadas aleatoriamente do nosso dataframe, foi necessário a utilização da função `rdply`.

A função `rdply`permite replicar o cálculo de uma expressão sem a necessidade de utilizar uma estrutura de repetição (ou *loop*), de modo a tornar a programação mais limpa e rápida. Além disso, os resultados dos cálculos efetuados são alocados em um novo dataframe, associados a um identificador (argumento `.id`, inserido na função `rdply`). 

Para separar o dataframe criado em 2000 amostras isoladas, podemos usar a função `split`, da biblioteca `plyr`. Poderíamos fazer, por exemplo, `amostra50 = split(amostra50, rep(1:2000, each = nrow(amostra50)/2000))`. Neste caso, seria criada uma lista com os 2000 dataframes. Essa talvez não seja a opção mais interessante, uma vez que irá ocupar muito espaço de memória. Uma alternativa, por exemplo, é fazer o *slice* do dataframe que é retornado da função `rdply`, por meio da coluna `.id`.


## Tamanho da Amostra e a Distribuição Amostral

Deixando de lado os aspectos técnicos de programação, vamos retomar a razão pela qual utilizamos a função `rdply`: calcular uma distribuição amostral, especificamente, esta aqui.


```{r}
medias_amostra50 %>%
  ggplot(aes(x = x_bar)) + 
  geom_histogram(
    aes(y = after_stat(density)), 
    binwidth = 10, 
    fill = "green", 
    col = "black") + 
  stat_function(
    fun = dnorm,
    args = 
      list(mean = mean(medias_amostra50$x_bar), sd = sd(medias_amostra50$x_bar)), 
    linewidth = 1, 
    color = "red"
    ) + 
  theme(text = element_text(size = 18)) + 
  labs(
    title = "Distribuição das médias amostrais",
    subtitle = "2000 amostras com n = 50 cada"
  )
```


A distribuição amostral que calculamos nos informa bastante sobre as estimativas da área habitável das casas na cidade de Ames. Uma vez que a média amostral é um estimador não viesado, a distribuição amostral estará centrada na verdadeira média da área habitável da população, e a dispersão da distribuição indica quanta variabilidade é possível ao se amostrar somente 50 vendas de casas.

Para ter uma ideia melhor do efeito do tamanho da amostra na distribuição amostral, vamos construir distribuições a partir de amostras de diferentes tamanhos:

**Passo 1**: Crie três distribuições amostrais, cada uma contendo 2000 médias amostrais, oriundas de amostras de tamanho $n=10$, $n=50$ e $n=100$.

```{r}
set.seed(123)
medias_amostra10 = rdply(2000, slice_sample(ames, n = 10, replace = T), .id = "id_sample") %>%
  group_by(id_sample) %>%
  summarise(x_bar = mean(area))
```

```{r}
set.seed(123)
medias_amostra100 = rdply(2000, slice_sample(ames, n = 100, replace = T), .id = "id_sample") %>%
  group_by(id_sample) %>%
  summarise(x_bar = mean(area))
```


**Passo 2**: Construa o gráfico dessas três distribuições amostrais, uma seguida da outra e, na mesma escala, de modo que possamos comparar as formas, centros e dispersões de cada uma.

* **Passo 2a**: Combine essas três distribuições amostrais (cada uma com 2000 valores) em um novo conjunto de dados contendo 6000 valores. Para combinar bancos de dados, linha por linha, nós usamos a função `rbind`.

* **Passo 2b**: Adicione uma nova coluna chamada `tamanho_amostra` aos dados que você acabou de criar, indicando o tamanho da amostra utilizado ao obter cada entrada. Lembre-se que os primeiros 2000 valores foram obtidos de amostras de tamanho 10, os 2000 seguintes de amostras de tamanho 50 e, finalmente, os 2000 últimos valores foram obtidos de amostras de tamanho 100. Portanto, essa nova variável é simplesmente a repetição do valor 10 por 2000 vezes, seguida de 50 por 2000 vezes e, novamente, 100 por 2000 vezes. O uso da função `factor` indica ao R que a variável é qualitativa, e não numérica. Lembre-se também de usar a função `mutate` para adicionar a nova variável ao banco de dados. O argumento `rep(c(10,50,100), each=2000)` diz ao R que os valores 10, 50 e 100 serão repetidos cada um 2000 vezes.


```{r}
medias_amostra = rbind(medias_amostra10, medias_amostra50, medias_amostra100) %>%
  select(-id_sample) %>%
  mutate(tamanho_amostra = factor(rep(c(10,50,100), each = 2000)))
```

* **Passo 2c**: Finalmente, construa os três gráficos representando estas três distribuições amostrais. Podemos fazer isso via *faceting*, i.e. criar faces separadas no gráfico para cada uma das distribuições. Lembre-se que nós identificamos cada distribuição a partir da variável `tamanho_amostra`, que acabamos de criar. A expressão `~tamanho_amostra` é nova: ela separa o eixo-y do nosso gráfico em três faces segundo o `tamanho_amostra` e não separa o eixo-x, o que significa que os gráficos serão dispostos um acima do outro ao invés de um ao lado do outro. Decidimos por esta abordagem para facilitar a comparação entre a posição e a dispersão das distribuições.


```{r}
medias_amostra %>%
  ggplot(aes(x = x_bar)) + 
  geom_histogram(binwidth = 20, fill = "orange", col = "black") + 
  facet_wrap(~tamanho_amostra, ncol = 1, strip.position =  "right") +
  theme(text = element_text(size = 18))
```


Vemos, portanto, que o aumento do tamanho da amostra tem pouca influência sobre o centro da distribuição (a média amostral, que é uma estimativa da média populacional). A dispersão, porém, diminui bastante com o aumento do tamanho da amostra.

Isso mostra, na prática, o que diz o teorema do limite central: a distribuição amostral da média é normal com média igual à média populacional e variância igual a $\sigma/\sqrt{n}$, em que $n$ é o tamanho da amostra e $\sigma$ é o desvio padrão populacional[@bussab_morettin]. Em outras palavras, podemos dizer que, se sorteamos aleatoriamente um número grande de amostras suficientemente grande, a distribuição da média amostral será normal, centrada na média da população e com variância inversamente proporcional ao tamanho das amostras.



## Por Sua Conta

Até agora, nós nos ocupamos em estimar a média da área habitável nas casas do município de Ames. Agora você tentará estimar a média dos preços das casas.


1. Retire uma amostra aleatória de tamanho 15 da variável `price` e calcule a média. Com essa amostra, qual é sua melhor estimativa pontual para a média populacional?


Como sabemos, um bom estimador para a média populacional é a média amostral $\bar{X}$, que é um estimador não viesado. Para esse caso, a média amostral seria:


```{r}
ames %>%
  select(price) %>%
  slice_sample(n = 15, replace = T) %>%
  summarise(x_bar = mean(price))
```


2. Já que você tem acesso à população, simule a distribuição amostral de $\bar{X}_{price}$, retirando 2000 amostras de tamanho 15 da população e calculando 2000 médias amostrais. Armazene essas médias em um vetor com o nome `medias_amostra15`. Crie um gráfico com os resultados, e então descreva a forma dessa distribuição amostral. Baseado nessa distribuição amostral, qual seria seu palpite para a média dos preços das casas na população? Por fim, calcule e informe a média populacional.


```{r}
set.seed(123)
medias_amostra15 = rdply(2000, slice_sample(ames, n = 15, replace = T), .id = "id_sample") %>%
  group_by(id_sample) %>%
  summarise(x_bar = mean(price))

medias_amostra15 %>%
  ggplot(aes(x = x_bar)) +
  geom_histogram(
    aes(y = after_stat(density)), 
    binwidth = 2000, 
    fill = "orange", 
    col = "black"
    ) + 
  labs(
    title = "Distribuição das médias amostrais dos preços",
    subtitle = "2000 amostras com n = 15 cada"
  ) + 
  theme(text = element_text(size = 18)) + 
  stat_function(
    fun = dnorm, 
    args = list(mean = mean(medias_amostra15$x_bar), sd = sd(medias_amostra15$x_bar)),
    linewidth = 1, 
    color = "red"
    )
```

Conforme podemos ver no histograma plotado logo acima, a forma da distribuição da média para essas 2000 amostras de tamanho 15 é de uma normal, como seria de esperar pelo teorema do limite central. Segundo esse histograma, a melhor estimativa para a média populacional seria em torno de $ 180.000,00.

Além disso, a média populacional dos preços dos imóveis do nosso conjunto de dados é igual a `r format(colMeans(select(ames, price)), scientific = F, decimal.mark = ",", big.mark = ".", nsmall = 2)` dólares.

3. Mude o tamanho da sua amostra de 15 para 150, e então calcule a distribuição amostral utilizando o mesmo método descrito acima, e guarde as médias em um novo vetor com o nome `medias_amostra150`. Descreva a forma dessa distribuição amostral e compare-a com a distribuição amostral para a amostra de 15 elementos. Com base nessa distribuição amostral, qual seria seu palpite sobre a média dos preços de vendas de casas no município de Ames?


```{r}
set.seed(123)
medias_amostra150 = rdply(2000, slice_sample(ames, n = 150, replace = T), .id = "id_sample") %>%
  group_by(id_sample) %>%
  summarise(x_bar = mean(price))

medias_amostra150 %>%
  ggplot(aes(x = x_bar)) +
  geom_histogram(
    aes(y = after_stat(density)), 
    binwidth = 2000, 
    fill = "orange", 
    col = "black"
    ) + 
  labs(
    title = "Distribuição das médias amostrais dos preços",
    subtitle = "2000 amostras com n = 150 cada"
  ) + 
  theme(text = element_text(size = 18)) + 
  stat_function(
    fun = dnorm, 
    args = list(mean = mean(medias_amostra150$x_bar), sd = sd(medias_amostra150$x_bar)),
    linewidth = 1, 
    color = "red"
    )
```

Como podemos ver no histograma acima, a forma da distribuição das médias para amostras de tamanho $n=150$ é também normal, como esperado. Além disso, vemos também que nossa melhor estimativa para a média populacional continua sendo em torno de 180.000 dólares. 

Comparando este caso com o da distribuição das médias dos preços para amostras de tamanho $n = 15$, vemos que a maior diferença está na dispersão em torno da média populacional, que no presente caso é menor.


4. Das distribuições amostrais calculadas nos exercícios 2 e 3, qual tem menor dispersão? Se estamos interessados em estimativas que estão mais próximas do valor verdadeiro, preferiríamos uma distribuição com uma dispersão pequena ou grande?


Conforme já discutido no item acima, a distribuição amostral com menor dispersão é aquela com maior $n$, que nesse caso é aquela com $n = 150$. Se estamos interessados em fazer um inferência a respeito do valor da média populacional, por exemplo, deveríamos preferir amostras com maior $n$, a fim de ter maior precisão.


```{r}
medias_amostra_price = rbind(medias_amostra15, medias_amostra150) %>%
  select(-id_sample) %>%
  mutate(tamanho_amostra = factor(rep(c(15, 150), each = 2000)))

medias_amostra_price %>%
  ggplot(aes(x = x_bar)) + 
  geom_histogram(
    aes(y = after_stat(density)), 
    fill = "green", 
    col = "black", 
    binwidth = 2000
    ) +
  facet_wrap(~tamanho_amostra, ncol = 1, strip.position = "right") +
  theme(text= element_text(size = 18))
```



# Lab05: Introdução à Regressão Linear


O filme [Moneyball](https://en.wikipedia.org/wiki/Moneyball_(film)) aborda a “busca pelo segredo do sucesso no beisebol”. O filme conta a história de um time de baixo orçamento, o Oakland Athletics, que acreditava que estatísticas pouco utilizadas, tal como a habilidade de um jogador chegar a uma base, prediziam melhor a habilidade de marcar pontos do que estatísticas mais comuns, como **home** **runs**, **RBIs** (runs batted in, pontos feitos quando um jogador estava rebatendo), e média de rebatidas. Contratar jogadores que se destacavam nessas estatísticas pouco utilizadas se mostrou muito mais econômico para o time.

Neste laboratório iremos explorar os dados de todos os 30 times da Liga Principal de Beisebol dos Estados Unidos e examinaremos a relação linear entre pontos marcados numa temporada e várias outras estatísticas dos jogadores. Nosso objetivo será resumir essas relações de maneira visual e numérica para identificar qual variável, se houver alguma, melhor nos ajuda a predizer os pontos marcados por um time numa temporada.



## Conteúdos abordados neste laboratório


* Gráfico de pontos
* Correlação Linear
* Método de Mínimos Quadrados Ordinários
* Modelo de Regressão Linear Simples


## Os dados

Vamos carregar os dados da temporada de 2011[^datasets]:


```{r}
load(file = "mlb11.Rdata")
```

Além dos pontos marcados (`runs`), este conjunto de dados contém sete variáveis tradicionalmente utilizadas: vez ao taco (`at_bats`), rebatidas (`hits`), rebatidas para fora do campo (`homeruns`), média de rebatidas (`bat_avg`), eliminações (`strikeouts`), bases roubadas (`stolen_bases`), e vitórias (`wins`). Também foram incluídas três novas variáveis: percentual de alcance de base (`new_onbase`), percentual de potência (`new_slug`), e alcance de base mais potência (`new_obs`). Para a primeira parte da análise consideraremos as sete variáveis tradicionais. Ao final do laboratório, você trabalhará com as novas variáveis por conta própria.


> Que tipo de gráfico você utilizaria para mostrar a relação entre `runs` e alguma outra variável numérica? Crie um gráfico dessa relação utilizando a variável `at_bats` como preditora. A relação parece ser linear? Se você soubesse o valor de `at_bats` de um time, você se sentiria confiante para utilizar um modelo linear para predizer o número de runs?

Para ter uma ideia da relação entre as duas variáveis, podemos usar um gráfico de pontos ou dispersão:


```{r}
  ggplot(data = mlb11, aes(x = at_bats, y = runs)) + 
  geom_point(size = 2, color = "red") + 
  labs(
    title = "gráfico de dispersão",
    subtitle = "Pontos marcados como função de vezes ao taco"
  ) + 
  theme(text = element_text(size = 18))
```


Apesar da expressiva dispersão dos dados, é possível perceber, a partir do gráfico de pontos mostrado, que existe uma tendência de crescimento linear direto do número de pontos marcados (`runs`) com o número de vezes ao taco (`at_bats`). Portanto, dado um modelo linear devidamente ajustado aos dados por meio de algum algoritmo adequado de otimização (como mínimos quadrados ordinários, por exemplo), poderíamos sim utilizar esse modelo linear para predizer o número de pontos marcados por um time na temporada, usando a variável `at_bats` como preditora.


Se a relação parece ser linear, podemos quantificar a força da relação utilizando o coeficiente de correlação.


```{r}
mlb11 %>%
  summarise(cor(runs, at_bats))
```


## Soma dos quadrados dos resíduos

> Nesta seção você irá utilizar uma função interativa, `plot_ss`, para investigar o que queremos dizer com “soma dos quadrados dos resíduos”. Você deverá rodar esta função em seu console, não no documento markdown. Para rodar esta função é necessário que o conjunto de dados `mlb11` esteja carregado em seu ambiente de trabalho.


Assim como utilizamos a média e o desvio padrão para resumir características importantes de uma única variável, podemos resumir a relação entre essas duas variáveis por meio de uma reta que melhor descreve sua associação. Utilize a seguinte função interativa para selecionar a linha que você acha que cruza a nuvem de pontos da melhor maneira.


```{r eval=FALSE}
plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = T)
```


Depois de executar esse comando, você será solicitado a clicar em dois pontos situados no gráfico para definir uma reta. Depois que você fizer isso, a reta que você especificou será mostrada na cor preta e os resíduos na cor azul. Perceba que há 30 resíduos, um para cada uma das 30 observações. Lembre-se que os resíduos são a diferença entre os valores observados e os valores preditos pela linha:

$$ e_i = y_i - \hat{y_i} $$
A maneira mais comum de se fazer uma regressão linear é selecionar a linha que minimiza a soma dos quadrados dos resíduos. Para visualizar o quadrado dos resíduos, você pode rodar novamente o comando de geração do gráfico e adicionar o argumento showSquares = `TRUE`.


```{r eval=FALSE}
plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = T)
```

Note que o resultado da função `plot_ss` fornece a inclinação (coeficiente angular) e o intercepto da sua reta, bem como a soma dos quadrados.


## O modelo linear

É bastante cansativo tentar obter a linha dos mínimos quadrados, ou seja, a reta que minimiza a soma dos quadrados dos resíduos, por meio de tentativa e erro. Ao invés disso, podemos utilizar a função `lm` no R para ajustar o modelo linear (também conhecido como linha de regressão).


```{r}
m1 = lm(formula = runs ~ at_bats, data = mlb11)
```

O primeiro argumento da função lm é a fórmula, descrita como `y ~ x`. O que a função faz é obter o modelo linear de `runs` (pontos marcados) em função de `at_bats` (vezes ao taco). Aqui, cabe um destaque para o operador `~` (tilde), que é usado para separar as variáveis dependentes e independentes em um modelo. Neste caso, a fórmula diz: *`runs` depende de `at_bats`*. O segundo argumento especifica que o R deve buscar no banco de dados `mlb11` as variáveis `runs` e `at_bats`.

A saída da função `lm` é um objeto que contém todas as informações que precisamos sobre o modelo linear que acabamos de ajustar. Podemos acessar essa informação utilizando a função `summary`.


```{r}
summary(m1)
```
Vamos analisar o resultado passo a passo. Primeiramente, a fórmula utilizada para descrever o modelo é apresentada no começo. Depois da fórmula você verá o resumo de cinco números dos resíduos. A tabela “Coefficients” (coeficientes) apresentada em seguida é fundamental; sua primeira coluna apresenta o intercepto-y do modelo linear e o coeficiente da variável `at_bats`. Com essa tabela, podemos descrever a reta de regressão de mínimos quadrados para o modelo linear:


$$ \hat{y_i} = -2789.2429 + 0.6305 \times at\_bats $$
Uma última informação que abordaremos sobre a saída da função `summary` é o “Multiple R-Squared” (R-quadrado Múltiplo), ou de maneira abreviada, $R^2$. O valor do $R^2$ representa a proporção de variabilidade na variável resposta que é explicada pela variável explicativa. Neste modelo, 37,3% da variabilidade dos pontos `runs` é explicada pelas vezes ao taco `at_bats`.

> Ajuste um novo modelo que utilize a variável `homeruns` para predizer `runs`. Utilizando as estimativas dos resultados do R, escreva a equação da reta de regressão. O que a inclinação (coeficiente angular) nos diz sobre a relação entre o sucesso de um time e seus home runs?


```{r}
m2 = lm(formula = runs ~ homeruns, data = mlb11)
summary(m2)
```

Nesse caso, ajustando um modelo linear que utiliza a variável `homeruns` para predizer a variável `runs`, obtemos a seguinte equação para a reta de regressão:


$$ \hat{y_i} = 415.2389 + 1.8345 \times homeruns $$
Ainda, o coeficiente angular nos diz que o número de pontos marcados (`runs`) cresce com o número de rebatidas fora do campo (`homeruns`) a uma taxa de 1,8345 vezes.

Para visualizarmos melhor a relação entre as duas variáveis, podemos plotar um gráfico de pontos:


```{r}
ggplot(data = mlb11, aes(x = homeruns, y = runs)) +
  geom_point(size = 2, col = "red") + 
  labs(
    title = "Gráfico de dispersão",
    subtitle = "pontos marcados como função das rebatidas fora do campo"
  ) + 
  theme(text = element_text(size = 18))
```


Além disso, podemos ver também o coeficiente de correlação entre as variáveis `runs` e `homeruns`:


```{r}
mlb11 %>%
  summarise(coef_cor = cor(runs, homeruns))
```


## Predição e erro de predição

Vamos criar um gráfico de dispersão com a reta de mínimos quadrados para `m1` disposta junto aos pontos.

```{r}
ggplot(data = mlb11, aes(x = at_bats, y = runs)) +
  geom_point(size = 2, col = "red") +
  stat_smooth(method = "lm", formula = y ~ x, se = F) + 
  labs(
    title = "Modelo linear ajustado",
    subtitle = "vezes ao taco como preditora dos pontos"
  ) + 
  theme(text = element_text(size = 18))
```

Aqui nós estamos literalmente adicionando uma camada ao topo de nosso gráfico. A função `stat_smooth` cria uma reta ao ajustar um modelo linear. Ela também pode nos mostrar o erro padrão `se` associado à nossa reta, mas iremos omitir essa saída por enquanto.

Esta linha pode ser utilizada para predizer $y$ em função do valor $x$. Quando as previsões associadas aos valores de $x$ são feitas além dos valores observados, nos referimos a elas como extrapolações e não é bem recomendado. Portanto, previsões realizadas à partir dos dados observados são mais confiáveis. Ela também é utilizada para computar os resíduos.


> Se o gerente de um time visse a reta de regressão de mínimos quadrados e não os dados reais, quantos pontos (`runs`) ele prediria para um time com 5.579 vezes ao taco (`at_bats`)? Esse valor superestima ou subestima o valor real, e por quanto? Em outras palavras, qual é o resíduo para esta predição?

Utilizando os valores dos parâmetros ajustados de acordo com a amostra, $\beta_0 = −2789.2429$ e $\beta_1 = 0.6305$, além da equação do nosso modelo de regressão ajustado, podemos escrever:

```{r}
p_marcados = as.double(subset(mlb11, at_bats == 5579, select = "runs"))

p_previstos = -2789.2429 + 0.6305*5579

cat(
  "Pontos previstos: ",
  p_previstos,
  "\nPontos marcados: ",
  p_marcados,
  "\nResíduo: ", 
  p_marcados - p_previstos, 
  "\nErro relativo absoluto: ", 
  abs((p_marcados - p_previstos)/p_marcados),
  "\n"
  )
```


Escrita alternativa para o trecho acima:


```{r eval=FALSE}
p_marcados = mlb11 %>%
  filter(at_bats == 5579) %>%
  select(runs) %>%
  as.double()

p_previstos = -2789.2429 + 0.6305*5579

cat(
  "Pontos previstos: ",
  p_previstos,
  "\nPontos marcados: ",
  p_marcados,
  "\nResíduo: ", 
  p_marcados - p_previstos, 
  "\nErro relativo absoluto: ", 
  abs((p_marcados - p_previstos)/p_marcados),
  "\n"
  )
```

Conforme podemos ver na saída da linha de código acima, o número de pontos previsto pelo modelo em função do número de vezes ao taco, para o caso em que `at_bats = 5579`, é igual a `r as.integer(p_previstos)`, ao passo que o número de pontos observados para esse número de vezes ao taco é `r as.integer(p_marcados)`. Vemos, portanto, que o modelo superestima um pouco o valor realmente observado. Vemos também que a diferença relativa entre os dois valores é de cerca de 2%.



## Diagnóstico do Modelo

Para avaliar se um modelo linear é confiável, precisamos verificar (1) a linearidade, (2) resíduos normalmente distribuídos, e (3) variância constante.

**Linearidade**: Você já verificou se a relação entre pontos (`runs`) e vezes ao taco (`at_bats`) é linear utilizando o gráfico de dispersão. Deveríamos também verificar essa condição utilizando um gráfico dos resíduos em função dos valores ajustados.


```{r}
ggplot(data = m1, aes(x = .fitted, y = .resid)) +
  geom_point(col = "red", size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed", linewidth = 1, col = "blue") + 
  labs(
    x = "valores ajustados",
    y = "Resíduos",
    title = "Modelo linear para runs x at_bats",
    subtitle = "Avaliação de viés nos resíduos"
  ) + 
  theme(text = element_text(size = 18))
```


Neste último gráfico, esperamos uma nuvem de pontos uniformemente distribuídos em torno da reta $x = 0$, o que indicaria resíduos com média aproximadamente igual a zero e ausência de vieses.

Note que o nosso objeto `m1` também funciona como um conjunto de dados, pois nele estão armazenados os valores ajustados ($\hat{y}$) e os resíduos. Observe tembém que nós utilizamos um código bem elegante aqui: depois de criar o gráfico de dispersão na primeira camada (primeira linha de código), nós adicionamos uma linha tracejada em $y=0$ (para nos ajudar a checar se os resíduos estão distribuiídos em torno de 0), e também nomeamos os eixos de modo a tornar o gráfico mais informativo.


> Há algum padrão aparente no gráfico de resíduos? O que isso indica sobre a linearidade da relação entre pontos (`runs`) e vezes ao taco (`at_bats`)?

Conforme podemos ver no gráfico de resíduos plotado, não há um padrão aparente (viés) na dispersão dos dados. Aparentemente, os resíduos estão dispostos aleatoriamente em torno de zero, o que é uma suposição incial em modelos de regressão. Contudo, a baixa quantidade de pontos dificulta um pouco a análise, já que alguns dos pontos estão muito afastados da reta tracejada.


**Resíduos aproximadamente normais**: Para verificar essa condição, podemos conferir o histograma dos resíduos:

```{r}
ggplot(data = m1, aes(x = .resid)) +
  geom_histogram(
    aes(y = after_stat(density)), 
    binwidth = 20, 
    col = "black", 
    fill = "orange"
    ) + 
  stat_function(
    fun = dnorm, 
    args = 
      list(mean = mean(m1$residuals), sd = sd(m1$residuals)),
    col = "red", 
    linewidth = 1
  ) + 
  labs(
    x = "Residuals",
    title = "Distribuição dos resíduos"
  ) + 
  theme(text = element_text(size = 20))
```

ou um QxQ-plot (quantis dos resíduos vs quantis teóricos da normal padrão). Nesse caso, esperamos que se os quantis seguirem a mesma distribuição (normal) eles devem estar posicionados sobre uma reta com orientação positiva.

```{r}
ggplot(data = m1, aes(sample = .resid)) + 
  geom_qq(col = "red", size = 2) + 
  geom_qq_line(linetype = "dashed", color = "blue", linewidth = 1) +
  labs(
    x = "Quantis teóricos",
    y = "Quantis amostrais",
    title = "Estudo da normalidade dos resíduos",
    subtitle = "q-q plot para os resíduos"
  ) + 
  theme(text = element_text(size = 20))
```

Note que a sintaxe para a construção deste gráfico é um pouco diferente do que você está aconstumado: nós indicamos `sample` para os resíduos aos invés de `x` (pois os dados provém de uma amostra, ou sample em inglês), e indicamos também o método estatístico `geom_qq()`, que significa “quantil-quantil” (QxQ), outro nome bem comum para este tipo de gráfico.

Conforme podemos obsersar no qXq plot e no histograma esboçado, os resíduos estão razoavlemente afastados da normalidade.

**Variância constante**: Essa condição pode ser verificada através da curva dos resíduos padronizados em função dos valores ajustados. Aqui, é importante ressaltar que essa condição também é conhecida como *homocedasticidade*.

Para verificar se um modelo de regressão linear ajustado atende aos pressupostos, podemos aplicar a função `plot()` à saída de `lm()`. Para entendermos qual será o resultado, podemos rodar o comando `?plot.lm`.


- A função `par()` é usada para definir parâmetros de gráficos

- O argumento `mfrow` divide o gráfico conforme uma matriz $n_r \times c_c$, plotando primeiro os quadros horizontais.

- A função `plot()`, quando aplicada a um objeto do tipo `lm()`, dispõe de 6 saídas:


1 - gráfico de dispersão para resíduos contra valores ajustados

2 - gráfico de localização da escala da raíz dos resíduos versus valores ajustados

3 - q-q plot para a distribuição normal

4 - gráfico de distâncias de Cook versus rótulos de linha

5 - resíduos versus alavancagem

6 - distâncias de Cook versus alavancagem


Por padrão, a saída apresenta as 3 primeiras e a quinta opções. Porém, outras podem ser selecionadas com o argumento `which`.


```{r}
par(mfrow = c(2, 2))
plot(m1, which = c(1:4), pch = 16)
```


Olhando para o terceiro quadro acima, vemos que a hipótese de homocedasticidade aproximada dos resíduos está verificada.


## Por sua conta

1. Escolha outra variável tradicional contida no banco de dados `mlb11`, diferente da variável `at_bats`, que você acha que poderia ser um bom preditor da variável `runs`. Crie um gráfico de dispersão das duas variáveis e ajuste um modelo linear. Visualmente, parece haver uma relação linear?


Vamos escolher a variável `hits` (rebatidas) como preditora. Deste modo, temos:


```{r}
ggplot(data = mlb11, aes(x = hits, y = runs)) + 
  geom_point(col = "red", size = 2) + 
  stat_smooth(method = "lm", formula = y ~ x, se = T) + 
  labs(
    title = "Ajuste para pontos em função da média de rebatidas",
    subtitle = "modelo de regressão linear, ajuste linear"
  ) + 
  theme(text = element_text(size = 18))

mlb11 %>%
  summarise(cor(hits, runs))
```


Como podemos ver no resultado acima, existe uma aparente relação linear entre as variáveis `runs` e `hits`, que é corroborada pelo valor de $\rho = 0.8012$.


2. Como essa relação se compara àquela existente entre `runs` e `at_bats`? Utilize os valores $R^2$ do sumário dos dois modelos para compará-los. A variável que você escolheu parece predizer `runs` melhor do que `at_bats`? Como você justificaria sua resposta?


Para responder a essas perguntas, primeiro vamos obter os parâmetros da regressão:


```{r}
m3 = lm(data = mlb11, formula = runs ~ hits)
summary(m3)
```

Conforme podemos concluir a partir dos valores do coeficiente de correlação entre as variáveis `hits`e `runs`, assim como a partir do valor do $R^2$ múltiplo, a relação linear entre as duas variáveis se mostra mais forte do que aquela existente entre `at_bats` e `runs`. De fato, no atual caso em análise, o valor do $R^2$ múltiplo é de aproximadamente 0.64, ao passo que no caso em que usamos a variável `at_bats` como preditora para `runs`, esse valor é de apenas 0.37. Portanto, concluímos que a variável `hits` (número de rebatidas) parece predizer melhor o número de pontos marcados pelo time na temporada do que o número de vezes ao taco (`at_bats`).

3. Agora que você pode resumir a relação linear entre duas variáveis, investigue a relação entre `runs` e cada uma das outras cinco variáveis tradicionalmente utilizadas no beisebol. Qual variável prediz melhor o valor de `runs`? Justifique sua conclusão utilizando métodos gráficos e numéricos já discutidos (para ser conciso, inclua apenas os resultados da melhor variável, não de todas as cinco).


Como já testamos 3 variáveis preditoras até agora (`at_bats`, `home_runs` e `hits`), vamos analisar as outras três e inserir cada resultado numa tabela:


```{r}
m4 = lm(data = mlb11, formula = runs ~ bat_avg)
m5 = lm(data = mlb11, formula = runs ~ strikeouts)
m6 = lm(data = mlb11, formula = runs ~ stolen_bases)
m7 = lm(data = mlb11, formula = runs ~ wins)
m8 = lm(data = mlb11, formula = runs ~ new_onbase)
m9 = lm(data = mlb11, formula = runs ~ new_slug)
m10 = lm(data = mlb11, formula = runs ~ new_obs)
```


```{r}
resultado1 = data.frame(
  var_predit = c("at_bats", "hits", "home_runs", "bat_avg", "strikeouts", "stolen_bases", "wins"), 
  r_square_mult = c(summary(m1)$r.squared, summary(m2)$r.squared, summary(m3)$r.squared, summary(m4)$r.squared, summary(m5)$r.squared, summary(m6)$r.squared, summary(m7)$r.squared), 
  cor_coef = c(cor(mlb11$runs, mlb11$at_bats), cor(mlb11$runs, mlb11$hits), cor(mlb11$runs, mlb11$homeruns), cor(mlb11$runs, mlb11$bat_avg), cor(mlb11$runs, mlb11$strikeouts), cor(mlb11$runs, mlb11$stolen_bases), cor(mlb11$runs, mlb11$wins))
  )

  kable(
    resultado1, 
    col.names = c("Variável Preditora", "R^2-múltiplo", "Coef. de Correlação")
    ) %>% 
    kable_styling(
      full_width = F, 
      bootstrap_options = c("striped", "hover", "condensed", "responsive")
      )
```

<br>


De acordo com a tabela apresentada acima, a melhor variável preditora para a variável `runs`, dentre as 7 listadas na tabela, é a variável `bat_avg` (média de rebatidas). Podemos ainda ver como fica a linha de regressão para esse caso:


```{r}
ggplot(data = mlb11, aes(x = bat_avg, y = runs)) +
  geom_point(col = "red", size = 2) + 
  stat_smooth(method = "lm", formula = y ~ x, se = T) + 
  labs(
    title = "Ajuste para runs como função de bat_avg",
    subtitle = "modelo de regressão linear, ajuste linear"
  ) + 
  theme(text = element_text(size = 18))
```


4. Agora examine as três variáveis mais recentes. Essas são as estatísticas utilizadas pelo autor do filme Moneyball para predizer o sucesso de um time. De modo geral, elas são mais ou menos eficazes para predizer os pontos (`runs`) se comparadas às variáveis mais tradicionais? Explique utilizando evidências gráficas e numéricas apropriadas. De todas as dez variáveis que nós analisamos, qual parece ser a melhor preditora da variável runs? Utilizando as informações limitadas (ou não tão limitadas) que você conhece sobre estas estatísticas do beisebol, seu resultado faz sentido?


```{r}
resultado2 = data.frame(
  var_predit = c("new_onbase", "new_slug", "new_obs"), 
  r_square_mult = c(summary(m8)$r.squared, summary(m9)$r.squared, summary(m10)$r.squared), 
  cor_coef = c(cor(mlb11$runs, mlb11$new_onbase), cor(mlb11$runs, mlb11$new_slug), cor(mlb11$runs, mlb11$new_obs)))

  kable(
    resultado2, 
    col.names = c("Variável Preditora", "R^2-múltiplo", "Coef. de Correlação")
    ) %>% 
    kable_styling(
      full_width = F, 
      bootstrap_options = c("striped", "hover", "condensed", "responsive")
      )
```


Conforme podemos ver na tabela acima, as estatísticas usadas no Filme [Moneyball](https://en.wikipedia.org/wiki/Moneyball_(film)) são melhores que todas as outras 7 tradicionalmente utilizadas para prever o número de pontos marcados por um time naquela temporada analisada. Dentre as novas estatísticas introduzidas, a variável `new_obs`é a que tem maior sucesso em predizer o número de pontos marcados por um time, considerando o $R^2$ múltiplo e o coeficiente de correlação entre a variável `runs` e a respectiva variável preditora.

De fato, podemos ver como fica a linha de regressão para esse caso:


```{r}
ggplot(data = mlb11, aes(x = new_obs, y = runs)) + 
  geom_point(col = "red", size = 2) +
  stat_smooth(method = "lm", formula = y ~ x, se = T) +
  labs(
    title = "Ajuste para runs como função de new_obs",
    subtitle = "modelo de regressão linear, ajuste linear"
  ) + 
  theme(text = element_text(size = 18))
```



5. Faça uma análise de diagnóstico do modelo de regressão a partir da variável que você escolheu como melhor preditora dos pontos (variável `runs`).


Para subsidiar a nossa análise, vamos aplicar a função `plot()` ao nosso modelo ajustado, `m10`, a fim de obter a avaliação dos resíduos do modelo.

```{r}
par(mfrow = c(2, 2))
plot(m10, which = c(1:4), pch = 16)
```

**Linearidade**


Como podemos ver no gráfico acima, os resíduos não apresentam um viés claro aparente. Porém, a hipótese de que a média dos resíduos é zero parece estar violada.


**Resíduos aproximadamente normais**


Conforme podemos ver no qq-plot mostrado acima, os resíduos amostrais se ajustam razoavelmente bem a uma distribuição normal.


**Variância constante**

Com base no resultado do terceiro quadro mostrado acima, vemos que a hipótese de homocedasticidade é aproximadamente válida, sendo que a variância parece diminuir levemente com o aumento dos valores ajustados.


Finalmente, dados o gráfico do modelo ajustado e a análise de resíduos feita acima, podemos concluir que o modelo linear adotado (percentual de alcance de base como preditora para os pontos marcados) parece razoavelmente adequado. Contudo, devemos ter um pouco de cautela, já que duas das hipóteses utilizadas para a construção do modelo parecem ser ligeiramente violadas. Tal fato pode decorrer do reduzido número de pontos para análise (30). 



# Lab06:


# Lab07: Inferência para dados numéricos


Neste laboratório, realizaremos testes de hipóteses e construíremos intervalos de confiança (IC's) para médias e diferenças de médias. Vamos fazer esses cálculos "manualmente" e através do uso de uma função nativa do R chamada `t.test()`, que é uma função extremamente útil e flexível quando a amostra bruta é dada. Às vezes, porém, só temos acesso a estatísticas da amostra (por exemplo, $\bar{x}, s_x, n$), o que exige que realizemos cálculos "manualmente" - ou seja, a função `t.test()` requer os dados brutos.


## Conteúdos abordados neste laboratório


* Intervalo de confiança
* Teste t para a média de uma população supostamente normal
* Teste t pareado e não pareado para a diferença entre duas médias



## Nascimentos na Carolina do Norte

Em 2004, o estado da Carolina do Norte, Estados Unidos, disponibilizou um grande conjunto de dados contendo informações sobre os nascimentos registrados no estado. Esse conjunto de dados é útil para pesquisadores que estudam a relação entre hábitos e práticas de gestantes e o nascimento de seus filhos. Nós trabalharemos com uma amostra aleatória das observações deste conjunto de dados.


## Análise Exploratória

Carregue o conjunto de dados `nc` em seu espaço de trabalho [@datasets].

```{r}
load("nc.RData")
```

Temos dados de 13 variáveis diferentes, algumas qualitativas e outras quantitativas. O significado de cada variável é o seguinte:


<center>

<table style="border-collapse:collapse;border-color:#aaa;border-spacing:0" class="tg"><thead><tr><th style="background-color:#f38630;border-color:#aaa;border-style:solid;border-width:1px;color:#fff;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:middle;word-break:normal"><span style="font-weight:700">variable</span></th><th style="background-color:#f38630;border-color:#aaa;border-style:solid;border-width:1px;color:#fff;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:middle;word-break:normal"><span style="font-weight:700">description</span></th></tr></thead><tbody><tr><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`fage`</span></td><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">father’s age in years.</td></tr><tr><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`mage`</span></td><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">mother’s age in years.</td></tr><tr><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`mature`</span></td><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">maturity status of mother.</td></tr><tr><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`weeks`</span></td><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">length of pregnancy in weeks.</td></tr><tr><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`premie`</span></td><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">whether the birth was classified as premature (premie) or full-term.</td></tr><tr><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`visits`</span></td><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">number of hospital visits during pregnancy.</td></tr><tr><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`marital`</span></td><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">whether mother is <span style="color:inherit">married</span> or <span style="color:inherit">not married</span> at birth.</td></tr><tr><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`gained`</span></td><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">weight gained by mother during pregnancy in pounds.</td></tr><tr><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`weight`</span></td><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">weight of the baby at birth in pounds.</td></tr><tr><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`lowbirthweight`</span></td><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">whether baby was classified as low birthweight (<span style="color:inherit">low</span>) or not (<span style="color:inherit">not low</span>).</td></tr><tr><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`gender`</span></td><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">gender of the baby, <span style="color:inherit">female</span> or <span style="color:inherit">male</span>.</td></tr><tr><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`habit`</span></td><td style="background-color:#fff;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">status of the mother as a <span style="color:inherit">nonsmoker</span> or a <span style="color:inherit">smoker</span>.</td></tr><tr><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="color:inherit">`whitemom`</span></td><td style="background-color:#FCFBE3;border-color:#aaa;border-style:solid;border-width:1px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:middle;word-break:normal">whether mom is <span style="color:inherit">white</span> or <span style="color:inherit">not white</span>.</td></tr></tbody></table>

</center>

<br>

Primeiro, vamos fazer um breve resumo desse conjunto de dados:

```{r}
cat("Número de Registros:",
    nrow(nc),
    "\nResumo Estatístico:\n"
    )

summary(nc)
```
Com a ajuda da função `glimpse()`, vamos ver quais dados são numéricos e quais são do tipo categórico:

```{r}
glimpse(nc)
```

Vamos agora investigar a idade típica das mães e pais na Carolina do Norte. Comecemos construindo histogramas, boxplots e verificando o resumo de cinco números para cada caso:


```{r}
histogram = nc %>%
  ggplot(aes(x = mage)) + 
  geom_histogram(
    col = "black", 
    fill = "pink", 
    binwidth = 1) + 
  labs(
    title = "Mother's age",
    x = "age",
    y = "N"
  ) + 
  theme(text = element_text(size = 18))

box_plot = nc %>%
  ggplot(aes(y = mage, x = "")) + 
  geom_boxplot(
    fill = "pink",
    outlier.colour = "red",
    alpha = 0.95,
    width = 0.4
  ) + 
  labs(
    x = "",
    y = ""
  ) +
  theme(text = element_text(size = 18))

cowplot::plot_grid(histogram, box_plot)
```



```{r}
histogram = nc %>%
  ggplot(aes(x = fage)) + 
  geom_histogram(col = "black", fill = "skyblue", binwidth = 1) + 
  labs(
    title = "Father's age",
    x = "age",
    y = "N"
  ) + 
  theme(text = element_text(size = 18))

box_plot = nc %>%
  ggplot(aes(y = fage, x = "")) + 
  geom_boxplot(
    fill = "skyblue",
    outlier.colour = "red",
    alpha = 0.95,
    width = 0.4
  ) + 
  labs(
    x = "",
    y = ""
  ) +
  theme(text = element_text(size = 18))

cowplot::plot_grid(histogram, box_plot)
```


```{r}
cat("Resumo de 5 números para a idade da mãe:\n")

summary(nc$mage)

cat("Resumo de 5 números para a idade do pai:\n")

summary(nc$fage)

cat("\nVariabilidade da idade da mãe:\n")

nc %>% 
  summarise(dq = IQR(mage, na.rm = T), s = sd(mage, na.rm = T))

cat("\nVariabilidade da idade do pai:\n")

nc %>% 
  summarise(dq = IQR(fage, na.rm = T), s = sd(fage, na.rm = T))
```

>Note que `sd(fage)` e `IQR(fage)` não retorna resultados válidos. O resumo de 5 números indica que existem 171 nascimentos para os quais a idade do pai não foi informada. Por padrão, a maioria das funções do R não retorna resultados válidos quando o dado está ausente. Isto pode ser resolvido adicionando-se o argumento `na.rm = TRUE` na chamada da função.


## Introdução à inferência

Suponha que queremos testar a hipótese de que a idade média para as mães que dão à luz na Carolina do Norte é 26,5 anos. Calculando "manualmente", temos[@bussab_morettin]:


```{r}
# Dados amostrais

xbar = mean(nc$mage)
std = sd(nc$mage)
n = length(nc$mage)

# Teste de hipótese -- Calculando o p-valor

dof = n - 1 #Graus de liberdade
std_err = std/sqrt(n) #erro padrão do estimador
test_stat = (xbar - 26.5)/std_err #Estatística do teste
p_value = 2*pt(-abs(test_stat), df = dof)
p_value

#Construindo um intervalo de confiança de 95% para a média:

q = qt(0.975, df = dof)
IC = xbar + c(-1, 1)*q*std_err
IC
```

Como o nosso p-valor é menor que o nível de significância $\alpha$ (0,05), temos evidências suficientes para rejeitar a hipótese de que a idade média das mulheres que dão à luz na Carolina do Norte é de 26,5 anos. Observe que 26,5 anos não está contido no intervalo de confiança de 95% construído. Os testes de hipóteses para a média com nível de significância $\alpha$ são logicamente equivalentes a um intervalo de confiança de $100(1 - \alpha)\%$ - essa é a grande sacada.

Vamos agora fazer o mesmo procedimento com o uso da função `t.test()`:

```{r}
# Mother's mean age -- HT and 95% CI

t.test(
  x = nc$mage, 
  alternative = "two.sided", 
  mu = 26.5, 
  conf.level = 0.95
  )
```

> Suponha agora que queiramos testar se a idade média dos pais da NC é 30 anos. Use $\alpha = 0.01$. Construa também um intervalo de confiança de 99% para a média. Calcule "manualmente" e usando `t.test()`. **Dica**: quando calculamos "manualmente", os valores ausentes podem ser um problema, de modo que primeiro precisamos extrair e armazenar as informações úteis. A função `t.test()`, por outro lado, já cuida disso automaticamente.


```{r}
# Dados Amostrais

# f_age = nc %>%
#   select(fage) %>%
#   drop_na()

xbar = mean(nc$fage, na.rm = T)
std = sd(nc$fage, na.rm = T)
n = sum(!is.na(nc$fage))

# Teste de hipótese - calculando o p-valor

dof = n - 1 #Graus de liberdade
std_err = std/sqrt(n) #Erro padrão do estimador
test_stat = (xbar - 30)/std_err #Estatística do teste

2*pt(-abs(test_stat), df = dof)

# Construindo um intervalo de confiança de 99% para a média:

q = qt(0.995, df = dof)
IC = xbar + c(-1, 1)*q*std_err
IC
```

Fazendo o mesmo cálculo usando a função `t.test()`, temos:

```{r}
t.test(
  x = nc$fage, 
  mu = 30, 
  alternative = "two.sided",
  conf.level = 0.99
  )
```

Suponha que um pesquisador quer testar a hipótese de que a média da idade dos pais na NC é diferente da média da idade das mães que deram à luz - suponha um $\alpha$ de 0,01. Este é um teste para a diferença entre as duas médias populacionais, o que nos obriga a perguntar se os dados para os dois grupos (mães e pais) são pareados ou não. Claramente, os dados são pareados, uma vez que as idades do pai e da mãe guardam relação de interdependência. Fazendo o cálculo primeiro "manualmente", temos:

```{r}
# Teste pareado - apenas é necessária a diferença nas idades

age_diff = nc$mage - nc$fage
summary(age_diff)

# Dados amostrais

xbar = mean(age_diff, na.rm = T)
std  = sd(age_diff, na.rm = T)
n = sum(!is.na(age_diff))

# Teste de hipótese - calculando o p-valor

dof = n - 1 #graus de liberdade
std_err = std/sqrt(n) #erro padrão do estimador
test_stat = (xbar - 0)/std_err #estatística do teste
2*pt(-abs(test_stat), df = dof)

# Construindo um intervalo de confiança de 99% para a média

q = qt(0.995, df = dof)
IC = xbar + c(-1, 1)*q*std_err
IC
```

E usando a função `t.test()`, nosso resultado sai muito mais rápido:


```{r}
# Opção 1: Calcular a diferença entre as duas variáveis externamente e
# inserí-la na função t.test()

t.test(x = age_diff, alternative = "two.sided", mu = 0, conf.level = 0.99)

# Opção 2: Faça a própria função calcular as diferenças, utilizando
# o argumento paired = TRUE

t.test(
  x = nc$mage, 
  y = nc$fage, 
  paired = T, 
  alternative = "two.sided",
  mu = 0,
  conf.level = 0.99
  )
```


> Conforme já discutido no texto, o teste t pareado é usado quando os dois conjuntos de dados cujas médias queremos comparar guardam relação de interdependência. Vimos o exemplo das idades de mães e pais de recém nascidos. Outro caso interessante é quando consideramos medidas de uma mesma grandeza e em um mesmo indivíduo em momentos diferentes - por exemplo, a pressão arterial do mesmo grupo de indivíduos antes e depois de administrar-se determinada droga.


Agora considere a relação entre o hábito de fumar de uma mãe e o peso de seu bebê. Plotar os dados é um primeiro passo útil, uma vez que nos ajuda a visualizar tendências rapidamente, identificar associações fortes e desenvolver questões de pesquisa.

> Faça um box plot lado-a-lado para `habit` e `weight`. O que o gráfico destaca sobre a relação entre essas duas variáveis?

```{r}
nc %>%
  drop_na() %>%
  ggplot(aes(x = "", y = weight, fill = habit)) + 
  geom_boxplot(
    width = 0.6,
    outlier.colour = "red",
    alpha = 0.95
    ) + 
  scale_fill_manual(values = c("green", "yellow")) + 
  theme_void() + 
  labs(
    title = "Peso dos recém-nascidos"
  ) +
  theme(text = element_text(size = 20))
```

Vemos, portanto, que as crianças filhos de mães não fumantes tendem a ter maior peso, embora existam muitos *outliers* com valores muito baixos.

Podemos ainda olhar para os pesos médios dos bebês dentro de cada grupo:

```{r}
nc %>%
  select(habit, weight) %>%
  drop_na() %>%
  group_by(habit) %>%
  summarise(media_peso = mean(weight)) %>%
  kable %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Corroborando aquilo que já dissemos acima, a média de peso para os bebês filhos de mães não fumantes parece ser maior do que a média para os filhos de mães fumantes. Mas será que essa diferença é significativa? Para responder a essa pergunta, faremos um teste de hipóteses.

> Verifique se as condições necessárias para a inferência são satisfeitas. Observe que você precisará obter tamanhos de amostra para verificar as condições. Você pode calcular o tamanho do grupo usando o mesmo comando acima, mas substituindo `mean` por `n()`.

```{r}
nc %>%
  group_by(habit) %>%
  summarise(n = n()) %>%
  drop_na() %>%
  kable %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Uma dsa condições para se fazer inferência estatística é o tamanho da amostra ser suficientemente grande, a qual garante a validade do teorema do limite central. Quanto maior o tamanho da amostra, melhor, mas em geral, uma amostra de tamanho $n = 100$ já é válida para inferências. Aqui, como estamos fazendo um teste t, é preciso também supor que os dados populacionais têm distribuição normal.


> Escreva as hipóteses para testar se os pesos médios dos bebês nascidos de mães fumantes e não fumantes são diferentes.

$$H_0: \mu_F = \mu_{NF}$$

$$H_1: \mu_F \neq \mu_{NF}$$

Novamente, este é um teste de hipótese para uma diferença entre duas médias, porém, neste caso, os dados não são pareados - não há uma maneira razoável de comparar membros de um grupo (fumantes) com o outro grupo (não fumantes). Não há razão para acreditar que os grupos sejam dependentes, uma vez que os registros foram amostrados aleatoriamente.

Primeiro, vamos fazer os cálculos "manualmente":


```{r}
# Estatísticas para os pesos dos bebês de mães fumantes:

grp1 = nc %>%
  subset(habit == "smoker", select = weight)
xbar1 = mean(grp1$weight, na.rm = T)
std1 = sd(grp1$weight, na.rm = T)
n1 = sum(!is.na(grp1))

# Estatísticas para os pesos dos bebês de mães não fumantes:

grp2 = nc %>%
  subset(habit == "nonsmoker", select = weight)
xbar2 = mean(grp2$weight, na.rm = T)
std2 = sd(grp2$weight, na.rm = T)
n2 = sum(!is.na(grp2))

# Teste de hipóteses - calculando o p-valor

A = std1^2/n1
B = std2^2/n2

dof = ((A+B)^2)/(A^2/(n1-1) + B^2/(n2-1)) #Graus de liberdade
std_err = sqrt(std1^2/n1 + std2^2/n2)
test_stat = (xbar1 - xbar2 - 0)/std_err #Estatística do teste
p_value = 2*pt(-abs(test_stat), df = dof)
p_value

# Construindo um intervalo de confiança de 95% para a diferença entre as
# médias:

q = qt(0.975, dof)
IC = xbar1 - xbar2 + c(-1, 1)*q*std_err
IC
```

Com a função `t.test()`, obtemos

```{r}
t.test(
  x = grp1$weight, 
  y = grp2$weight, 
  alternative = "two.sided",
  var.equal = F,
  paired = F,
  mu = 0,
  conf.level = 0.95
  )
```

Nesse último caso, o parâmetro `var.equal = F` é usado para indicar se estamos dispostos a assumir que os dois grupos têm variância igual. Na maioria dos casos, é mais seguro não fazer essa suposição.


## Por sua conta

1. Calcule um intervalo de confiança de 95% para a duração média das gestações (weeks) e interprete-o no contexto.


```{r}
duration = nc %>%
  select(weeks) %>%
  drop_na()

xbar = mean(duration$weeks)
n = nrow(duration)
std = sd(duration$weeks)
std_err = std/sqrt(n)
dof = n - 1
q = qt(0.975, df = dof)
IC = xbar + c(-1, 1)*q*std_err

cat(
  "Intervalo de Confiança p/ a duração média da gestação:",
  IC,
  "\nAmplitude do IC(95%):",
  abs(IC[1] - IC[2])
  )
```


2. Calcule um novo intervalo de confiança para o mesmo parâmetro no nível de confiança de 90%.


```{r}
q = qt(0.95, df = dof)
IC = xbar + c(-1, 1)*q*std_err
cat(
  "Intervalo de Confiança p/ a duração média da gestação:",
  IC,
  "\nAmplitude do IC(90%):",
  abs(IC[1] - IC[2])
  )
```


3. Agora, uma tarefa de não inferência: determine a idade de corte para mães mais jovens e maduras. Use um método de sua escolha e explique como seu método funciona.

Vamos escolher o terceiro quartil como critério para definir a idade das mães mais jovens e mais maduras:


```{r}
q3 = as.double(quantile(nc$mage, 0.75))
q3
```


4. Faça um teste de hipóteses avaliando se o peso médio ganho pelas mães mais jovens é diferente do peso médio ganho pelas mães maduras.

Primeiro, vamos definir as hipóteses nula e alternativa:

$$ H_0: \mu_{young} = \mu_{older} $$
$$ H_1: \mu_{young} \neq \mu_{older} $$
Agora, vamos fazer o teste de hipóteses propriamente dito. Primeiro, vamos dividir o conjunto de dados em dois grupos: o das mães mais jovens e o das mães mais velhas, os quais estão separados pelo terceiro quartil da idade. Após isso, de posse dos valores de peso ganho para os dois grupos, vamos fazer o teste estatístico.


```{r}
# Subdividindo o conjunto segundo as idades das mães mais velhas
older = nc %>%
  filter(mage >= q3) %>%
  select(gained) %>%
  drop_na()

# Estatísticas da amostra de mães mais velhas
xbar1 = mean(older$gained)
std1 = sd(older$gained)
n1 = nrow(older)

# Subdividindo o conjunto segundo as idades das mães mais jovens
younger = nc %>%
  filter(mage < q3) %>%
  select(gained) %>%
  drop_na()

# Estatísticas da amostra de mães mais jovens
xbar2 = mean(younger$gained)
std2 = sd(younger$gained)
n2 = nrow(younger)

# Vamos testar a igualdade das variâncias
var.test(older$gained, younger$gained)

# O resultado para o teste de igualdade das variâncias indica que as 
# variâncias dos dois grupos são iguais. Essa informação será levada
# em conta no teste t.

t.test(
  older$gained, 
  younger$gained, 
  var.equal = T,
  paired = F,
  alternative = "two.sided")
```
Conforme o resultado do teste t realizado aponta, há indícios de que o peso médio ganho pelas mães mais jovens e maduras são diferentes. Ainda, como a estatística do teste resultou ser negativa, concluímos também que o peso médio ganho pelas mães mais jovens é maior do que o ganho pelas mães mais maduras.

Por fim, sempre é bom lembrar que, quando estamos fazendo um teste t (que é um teste paramétrico), estamos supondo que conhecemos a distribuição das populações, que, neste caso, tem que ser normal. Para um resultado mais fidedigno, precisaríamos fazer um teste não paramétrico, como por exemplo, o teste de Mann-Whitney.

5. Escolha um par de variáveis numéricas e categóricas e crie uma questão de pesquisa avaliando a relação entre essas variáveis. Formule a questão de forma que possa ser respondida usando um teste de hipótese e/ou um intervalo de confiança. Responda sua pergunta usando a função `t.test()`, relate os resultados estatísticos e também forneça uma explicação em linguagem simples.


Podemos investigar a relação existente entre o número de visistas ao hospital que as mães fizeram durante a gestação (`visits`) e a cor da pele. Primeiro, vamos ver essa relação por meio de um boxplot:

```{r}
nc %>%
  select(visits, whitemom) %>%
  drop_na() %>%
  ggplot(aes(x = "", y = visits, fill = whitemom)) + 
  geom_boxplot(
    outlier.color = "red",
    alpha = 0.95,
    width = 0.4
    ) + 
  theme_void() + 
  theme(text = element_text(size = 20))
```

Aparentemente, não há grande diferenças entre o número de visitas feitas ao hospital durante a gravidez entre mulheres brancas e não brancas, ao menos do ponto de vista da mediana dos dados. 

Vamos fazer um teste baseado no número médio de visitas ao hospital feitas pelos dois grupos de mães - brancas e não brancas, supondo, claro, que as populações são normais. Vamos formular as hipóteses:


$$ H_0: \mu_{white} = \mu_{notwhite} $$

$$ H_1: \mu_{white} \neq \mu_{notwhite} $$


```{r}
# Separando os dois grupos: mães brancas e não brancas
white = nc %>%
  filter(whitemom == "white") %>%
  select(visits) %>%
  drop_na()

nwhite = nc %>%
  filter(whitemom != "white") %>%
  select(visits) %>%
  drop_na()

# Testando a igualdade das variâncias dos dois grupos

var.test(white$visits, nwhite$visits)

# Conforme o resultado do teste F para igualdade das variâncias, feito acima, concluímos que as variâncias dos dois grupos são diferentes.

# Testando a igualdade das médias dos dois grupos:

t.test(
  white$visits, 
  nwhite$visits, 
  var.equal = F, 
  paired = F, 
  alternative = "two.sided"
  )
```

Assim, de acordo com o resultado do nosso teste, rejeitamos a hipótese nula de que o número médio de visitas ao hospital é igual para os dois grupos de mães. Em outras palavras, concluímos que há indícios de que as mães brancas, em média, visitaram o hospital mais vezes que as mães não brancas durante a gravidez.



# Lab08: Mais inferência para dados numéricos - comparando várias amostras


Neste laboratório, daremos continuidade aos exemplos de inferência estatística. Porém, aqui, levaremos também em consideração comparações entre mais de duas populações, situação em que teremos que utilizar método ainda não visto no laboratório anterior.


## Conteúdos abordados neste laboratório


* Intervalo de confiança
* Teste t para a diferença entre duas médias
* Teste F para a igualdade entre as variâncias de duas populações normais
* ANOVA
* Correção de Bonferroni


## Salários Americanos


Neste laboratório, nós iremos trabalhar com uma amostra aleatória de 2000 observações do ACS (American Community Survey, ou Pesquisa da Comunidade Americana) 2012. Este conjunto de dados contém informações sobre a força de trabalho e os salários americanos. Você deve carregar esse banco de dados à partir do comando abaixo[@datasets].


```{r}
load("acs12.RData")
```


Temos dados de 13 variáveis diferentes, algumas qualitativas e outras quantitativas. Cada variável representa uma das seguintes informações:


<center>

<table style="border-collapse:collapse;border-color:#9ABAD9;border-spacing:0" class="tg"><thead><tr><th style="background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#fff;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">Variable</th><th style="background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#fff;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">Description</th></tr></thead><tbody><tr><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`income`</td><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Annual income</td></tr><tr><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`employment`</td><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Employment status</td></tr><tr><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`hrs_work`</td><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Hours worked per week</td></tr><tr><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`race`</td><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Race</td></tr><tr><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`age`</td><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Age, in years</td></tr><tr><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`gender`</td><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Gender</td></tr><tr><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`citizen` </td><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Whether the person is a U.S. citizen</td></tr><tr><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`time_to_work`</td><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Travel time to work, in minutes</td></tr><tr><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`lang`</td><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Language spoken at home</td></tr><tr><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`married`</td><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Whether the person is married</td></tr><tr><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`edu`</td><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Education level</td></tr><tr><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`disability`</td><td style="background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Whether the person is disabled</td></tr><tr><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">`birth_qrtr`</td><td style="background-color:#D2E4FC;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">The quarter of the year that the person was born, e.g. Jan thru Mar</td></tr></tbody></table>

</center>

</br>

Note que este conjunto de dados contém algumas pessoas que não estão na força de trabalho ou estão desempregadas, como podemos ver por meio dos comandos abaixo:


```{r}
glimpse(acs12$employment)

levels(acs12$employment)
```


```{r}
acs12 %>%
  select(employment) %>%
  group_by(employment) %>%
  summarise(
    n = n(), 
    percent = scales::percent(n()/nrow(acs12), accuracy = NULL)
    ) %>%
  kable() %>%
   kable_styling(
     full_width = F, 
     bootstrap_options = c("striped", "hover", "condensed", "responsive")
     )
```

Primeiramente, vamos filtrar os entrevistados que estão empregados. Vamos chamar este banco de dados como `acs_emp`.


```{r}
acs_emp = acs12 %>%
  filter(employment == "employed")
```

Podemos ver assim que o percentual de empredados na nossa amostra é de `r scales::percent(nrow(acs_emp)/nrow(acs12))`.

Agora, vamos dar um olhada na distribuição da renda de acordo com o gênero. O primeiro passo é criar uma visualização:

```{r}
acs_emp %>%
  ggplot(aes(y = income, x = "", fill = gender)) + 
  geom_boxplot(
    outlier.colour = "red",
    width = 0.4,
    alpha = 0.95
  ) + 
  theme_void() + 
  theme(text = element_text(size = 18)) + 
  scale_fill_manual(values = c("skyblue", "pink"))
```

Como podemos ver nos boxplots, os homens parecem ganhar mais que as mulheres.

Podemos também obter algumas estatísticas descritivas como a média, desvio padrão e tamanho das amostras.

```{r}
acs_emp %>%
  group_by(gender) %>%
  summarise(
    media = mean(income),
    dp = sd(income),
    n = n()
  ) %>%
   kable() %>%
   kable_styling(
     full_width = F, 
     bootstrap_options = c("striped", "hover", "condensed", "responsive")
     )
```

Assim, à primeira vista, os homens parecem ganhar muito mais que as mulheres, em média.

> Construa um intervalo de confiança de 95% para a diferença entre os rendimentos médios dos homens e mulheres e interprete este intervalo.

Supondo a normalidade dos dados nas respectivas populações, podemos escrever um intervalo de confiança de 95% para a diferença entre as rendas médias de homens e mulheres, por meio da distribuição t de Student:


```{r}
# Renda dos homens
income_male = acs_emp %>%
  filter(gender == "male") %>%
  select(income) %>%
  drop_na()

xbar1 = mean(income_male$income)
std1 = sd(income_male$income)
n1 = nrow(income_male)

# Renda das mulheres
income_female = acs_emp %>%
  filter(gender == "female") %>%
  select(income) %>%
  drop_na()

xbar2 = mean(income_female$income)
std2 = sd(income_female$income)
n2 = nrow(income_female)

# Testando a igualdade das variâncias
var.test(income_male$income, income_female$income)

# Portanto, como o teste F para igualdade das variâncias indicou que as variâncias dos dois gêneros são diferentes, o número de graus de liberdade para o teste t será dado por:
A = std1^2/n1
B = std2^2/n2

dof = ((A+B)^2)/(A^2/(n1-1) + B^2/(n2-1)) #Graus de liberdade
std_err = sqrt(std1^2/n1 + std2^2/n2) #Erro padrão do estimador
q = qt(0.975, df = dof) #Quantil que define o IC de 95%

IC = xbar1 - xbar2 + c(-1,1)*q*std_err

cat(
  "Intervalo de confiança para a diferença entre as médias:\n",
  IC
  )
```

Como o intervalo de confiança para a diferença entre as rendas médias dos homens e das mulheres não contêm o zero, concluímos que as duas médias são diferentes. Além disso, o sinal da diferença também indica que a renda média dos homens é de fato maior que a das mulheres.


> Qual é o nível de significância para o teste de hipóteses equivalente ao intervalo de confiança construído que avalia se existe uma diferença significativa entre os rendimentos médios de homens e mulheres?

Como sabemos, um intervalo de confiança de $100 \cdot \gamma \%$ equivale a um nível se significância $\alpha = 1 - \gamma$, Assim, se estamos escrevendo um intervalo de confiança de 95%, isso equivale a um teste de hipóteses com nível de significância $\alpha = 0.05$.

> Realize este teste de hipóteses e interprete seus resultados no contexto dos dados e da questão de pesquisa. Seus resultados do intervalo de confiança e do teste de hipóteses concordam?

Podemos fazer um teste t para a diferença entre a renda média de homens e mulheres, supondo populações normais:

```{r}
# Como sabemos que as variâcias dos dois grupos são muito diferentes, podemos supor diretamente que essas diferenças também ocorrem nas populações. 

# Fazendo o teste t não pareado para a diferença entre as duas médias
t.test(
  income_male$income, 
  income_female$income, 
  paired = F,
  alternative = "two.sided"
  )
```

Como $p \approx 0$, rejeitamos a hipótese de iguldade das duas médias para qualquer um dos intervalos de significância comumente adotados, o que está em perfeito acordo com o intervalo de confiança já escrito no item anterior. Além disso, a função `t.test()` também retorna o intervalo de confiança de 95% para a diferença entre as médias, e o resultado é o mesmo já calculado anterioriormente de maneira "manual".


## Variáveis de confusão

Há uma clara diferença entre os salários médios dos homens e das mulheres, mas poderia alguma, ou a totalidade, desta diferença ser atribuída a alguma outra variável que não seja o gênero? Nós chamamos tais variáveis como **variáveis de confusão**. Vamos avaliar se a variável `hrs_work` confunde a relação entre gênero e renda. Mas antes de fazermos isso, vamos primeiro converter a variável `hrs_work` a uma variável qualitativa (com níveis de "integral" e "parcial") para que possamos usar os métodos que aprendemos até agora na execução da análise.


## Convertendo variáveis

Queremos criar uma nova variável, digamos `emp_type`, com níveis de "integral" ou "partial", relacionados ao fato do empregado trabalhar 40 horas ou mais por semana ou menos do que 40 horas, respectivamente. Lembre-se que nós podemos adicionar uma nova variável ao conjunto de dados por meio da função `mutate`.


```{r}
acs_emp = acs_emp %>%
  mutate(
    emp_type = ifelse(hrs_work >= 40, "integral", "partial")
  )
```

A função `ifelse()` tem três argumentos: um teste lógico, retorna valores `TRUE` para os elementos verdadeiros do teste, e valores `FALSE` para elementos falsos do teste. Neste caso, `emp_type` será codificado como "integral" para observações onde `hrs_work` é maior ou igual a 40, e "partial" para o caso contrário.

Para descobrir a proporção de cada caso, nós retornamos às estatísticas descritivas:


```{r}
acs_emp %>%
  group_by(emp_type) %>%
  summarise(
    time_ratio = scales::percent(n()/nrow(acs_emp))
  ) %>%
  kable() %>%
   kable_styling(
     full_width = F, 
     bootstrap_options = c("striped", "hover", "condensed", "responsive")
     )
```

Aqui, primeiramente, nós agrupamos os dados pela nova variável `emp_type`, e então calculamos as proporções de trabalhadores a tempo integral e parcial ao contar quantos elementos existem em cada grupo (com a função `n()`), e em seguida dividimos esse número pelo total de linhas do conjunto de dados.

> Contrua um gráfico de barras da distribuição da variável `emp_type`, e também inclua as estatísticas descritivas que você calculou acima em sua resposta. Qual o percentual da amostra representa os trabalhadores em tempo integral e tempo parcial?

```{r}
acs_emp %>%
  ggplot(aes(x = emp_type, group = gender)) + 
  geom_bar(
    aes(y = after_stat(prop), fill = gender), 
    stat = "count", 
    position = "dodge"
    ) + 
  geom_text(
    aes(label = scales::percent(after_stat(prop)), y = after_stat(prop)),
    stat = "count",
    position = position_dodge(.9), 
    vjust = -0.5,
    size = 4.5
    ) + 
  # scale_y_continuous(labels = scales::percent) + 
  theme_minimal() + 
  labs(
    x = "",
    y = ""
  ) + 
  theme(
    axis.text.y=element_blank(),
    axis.ticks.y=element_blank()
    ) + 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank()
    ) + 
  theme(text = element_text(size = 18)) + 
  scale_fill_manual(values = c("skyblue", "pink"))
```


Aqui, temos uma pista para o motivo de as mulheres ganharem menos que os homens, em média. Quando olhamos para a variável `emp_type`, vemos que 29% da força de trabalho nesse dataframe trabalham em período parcial. Quando olhamos o gráfico de barras para a mesma variável, agrupado pelo gênero, vemos que, dentre as mulheres, cerca de metade trabalham em período parcial, enquanto que nos homens, esse percentual é menor que 20%.

Assim, concluímos que a menor renda das mulheres quando comparada à dos homens PODE ser devido à diferença nos regimes de trabalho, uma vez que, dentre os homens, apenas 19% trbalham em período parcial, ao passo que, dentre as mulheres, esse percentual é de 43%.


## Por sua conta

1. Crie dois subconjuntos do conjunto de dados `acs_emp`: um para trabalhadores a tempo integral e um outro para os trabalhadores a tempo parcial. Nenhuma interpretação é necessária para esta questão, apenas o código é suficiente.


```{r}
partial = acs_emp %>%
  filter(emp_type == "partial")

integral = acs_emp %>%
  filter(emp_type == "integral")
```

2. Use um teste de hipóteses para avaliar se existe diferença na renda média dos trabalhados masculinos e femininos que trabalham em tempo integral. Se a diferença for significativa, inclua um intervalo de confiança (equivalente ao nível de significância do teste) estimando a magnitude da diferença na renda média.

Podemos fazer um teste t, supondo a normalidade dos dados:

```{r}
# Renda dos homens
income_male_integral = integral %>%
  filter(gender == "male") %>%
  select(income) %>%
  drop_na()

# Renda das mulheres
income_female_integral = integral %>%
  filter(gender == "female") %>%
  select(income) %>%
  drop_na()

teste_t = t.test(
  income_male_integral$income, 
  income_female_integral$income,
  paired = F,
  var.equal = F,
  alternative = "two.sided")

teste_t
```


Como $p << 0.05$, concluímos que, provavelmente, existe diferença nas rendas médias de homens e mulheres que compõem a força de trabalho americana.


```{r}
cat(
  "Intervalo de confiança de 95% para a diferença nas rendas médias de homens e mulheres que trabalham em tempo integral:\n",
  teste_t$conf.int[1:2])
```

Portanto, vemos que, mesmo entre as pessoas que trabalham em tempo integral, existe uma diferença estatisticamente significativa entre as rendas médias de homens e mulheres.

3. Use um teste de hipóteses para avaliar se existe diferença na renda média dos trabalhados masculinos e femininos que trabalham em tempo parcial. Se a diferença for significativa, inclua um intervalo de confiança (equivalente ao nível de significância do teste) estimando a magnitude da diferença na renda média.

Novamente, podemos fazer um teste t, supondo a normalidade dos dados:

```{r}
# Renda dos homens
income_male_partial = partial %>%
  filter(gender == "male") %>%
  select(income) %>%
  drop_na()

# Renda das mulheres
income_female_partial = partial %>%
  filter(gender == "female") %>%
  select(income) %>%
  drop_na()

teste_t = t.test(
  income_male_partial$income, 
  income_female_partial$income,
  paired = F,
  var.equal = F,
  alternative = "two.sided")

teste_t
```

Como $p \approx 0.19 > 0.05$, concluímos que a diferença nas rendas médias de homens e mulheres que trabalham em tempo parcial não é significativa. Portanto, as rendas média são provavelmente iguais para aqueles que trabalham menos que 40 horas semanais.

4. O que os resultados do seu teste de hipóteses sugerem sobre as horas trabalhadas (em tempo integral ou parcial) constituirem ou não uma variável de confusão na relação entre gênero e renda?

Conforme comentado acima, concluímos que a quantidade de horas trabalhadas é de fato uma variável de confusão, uma vez que o resultado do teste de hipóteses muda quando consideramos apenas aqueles que trabalham menos de 40 horas semanais. Quando consideramos os que trabalham 40 horas ou mais, por outro lado, o resultado permanece o mesmo.

5. Que tipo de teste deveríamos utilizar para compararmos os salários médios em torno dos vários grupos de raça/etnia neste conjunto de dados? Explique seu raciocínio.

Primeiro, vamos ver quantos grupos existem para o fator raça no conjunto de dados completo:


```{r}
levels(acs12$race)
```

Portanto, vemos que temos 4 grupos dentro do fator raça. Quando queremos comparar as médias de mais que dois grupos, podemos usar um teste ANOVA (*Analysis of Variance*). Esse teste se baseia na variabilidade dentro dos grupos e entre os grupos e utiliza a distribuição F para testar a hipótese de igualdade entre as médias de todos os grupos contra a hipótese alternativa de que a média de pelo menos um grupo é diferente das demais.

6. Realize este teste de hipóteses utilizando a função inference. Note que a variável resposta é a renda e a variável explicativa é raça. Você terá que descobrir os argumentos restantes para a função. Use uma abordagem de tentativa e erro, e deixe que os erros o informe sobre o que mais precisa ser especificado, e como. (Nota: Utilize o conjunto de dados que contém os registros de todos os funcionários participantes: nomeie acs_map) Escreva suas hipóteses, e interprete a sua conclusão no contexto dos dados e da questão de pesquisa. Note que a função inference, por padrão, usa um nível de significância de 0,05 para a ANOVA, serão executados pares de testes t e p-valores serão reportados para eles, se a ANOVA for significativa. (Note também que você pode mudar o nível de significância definindo sig_level igual a algum outro valor.)

Aqui, podemos combinar as funções `aov()` e `anova()` para gerar o resultado do teste.


```{r}
anova1 = aov(income ~ race, acs12)
result = anova(anova1)
result
rsq = result$`Sum Sq`[1]/sum(result$`Sum Sq`)

cat(
  "Coeficiente de explicação do modelo utilizado",
  rsq
)
```

Com o resultado do teste acima, vemos que devemos rejeitar a hipótese nula de igualdade das rendas médias para os 4 diferentes grupos, já que p < 0,05. Porém, devemos também notar que os diferentes grupos só respondem por cerca de 1,5% da variabilidade dos dados como um todo. Sendo assim, a maior parte da variância desse conjunto de dados é devida a outros fatores.

Agora que rejeitamos a hipótese de igualdade das médias, podemos compará-las duas a duas, por meio da construção de intervalos de confiança para cada comparação, utilizando o fator de correção de Bonferroni[@bussab_morettin]. Esse fator corrige o nível de significância para as comparações dois a dois, considerando o nível de significância global. Caso a correção não fosse considerada, o nível de significância global não seria mantido ao fazer as comparações dois a dois, e poderíamos obter diferenças espúrias entre as médias.


O fator de correção de Bonferroni considera que o nível de significância que deve ser usado em cada comparação deve ser igual a $\alpha^*/m$, em que $\alpha^*$ é o nível de significância global do teste e $m$ é o número de comparações a ser feitas. Vamos considerar aqui o número máximo de comparações, que é igual a $C_{4,2}$, já que temos 4 níveis para o fator `race`.

Vamos primeiro listar as possíveis comparações, utilizando para isso a biblioteca `combinat`:


```{r}
config = combn(levels(acs12$race), 2)
config #configurações possíveis
m = ncol(config) #número de comparações possíveis
I = length(levels(acs12$race)) #número de grupos
```

Agora, vamos calcular as estatísticas de cada grupo, para então podermos escrever os IC's:


```{r}
grupos = acs12 %>%
  group_by(race) %>%
  summarise(
    n = n(),
    xbar = mean(income, na.rm = T),
    s = sd(income, na.rm = T)
  )
grupos %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Agora, vamos calcular o desvio padrão dentro dos grupos $S_e$, o qual pode ser determinado a partir do resultado da ANOVA ($QMDen$) e o erro padrão para cada comparação:


```{r}
#Tamanho de cada grupo
n1 = grupos$n[1]
n2 = grupos$n[2]
n3 = grupos$n[3]
n4 = grupos$n[4]

#Tamanho do conjunto de dados
n = nrow(acs12)

#Devio padrão dos resíduos
se = sqrt(result$`Mean Sq`[2])

#white-black
ep12 = se*sqrt(1/n1 + 1/n2)
#white-asian
ep13 = se*sqrt(1/n1 + 1/n3)
#white-other
ep14 = se*sqrt(1/n1 + 1/n4)
#black-asian
ep23 = se*sqrt(1/n2 + 1/n3)
#black-other
ep24 = se*sqrt(1/n2 + 1/n4)
#asian-other
ep34 = se*sqrt(1/n3 + 1/n4)

#quantil para o IC de 95%, com fator de correção
qb = qt(1-(1/m)*0.05/2, df = n-I)
```


Finalmente, vamos determinar os IC's para cada comparação:


```{r}
cat(
  "IC(mu1 - mu2; 95%) =",
  grupos$xbar[1] - grupos$xbar[2] + c(-1,1)*qb*ep12,
  "\nIC(mu1 - mu3; 95%) =",
  grupos$xbar[1] - grupos$xbar[3] + c(-1,1)*qb*ep13,
  "\nIC(mu1 - mu4; 95%) =",
  grupos$xbar[1] - grupos$xbar[4] + c(-1,1)*qb*ep14,
  "\nIC(mu2 - mu3; 95%) =",
  grupos$xbar[2] - grupos$xbar[3] + c(-1,1)*qb*ep23,
  "\nIC(mu2 - mu4; 95%) =",
  grupos$xbar[2] - grupos$xbar[4] + c(-1,1)*qb*ep24,
  "\nIC(mu3 - mu4; 95%) =",
  grupos$xbar[3] - grupos$xbar[4] + c(-1,1)*qb*ep34
)
```

$$ \mu_{white} = \mu_{other} > \mu_{black} < \mu_{asian} $$


Poderíamos também fazer todas essas comparações entre pares de médias por meio da função `PostHocTest`, da biblioteca `Desctools`, o que pouparia muito trabalho:

```{r}
PostHocTest(anova1, method = "bonferroni", conf.level = 0.95)
```


7. Escolha outra variável numérica à partir do conjunto de dados para ser a variável resposta, e também escolha uma variável explicativa qualitativa (pode ser uma que usamos antes). Realize o teste de hipóteses apropriado, utilizando a função inference, para comparar as médias da variável resposta entre os diferentes casos da variável explicativa. Certifique-se de indicar a sua questão de pesquisa, e interpretar a sua conclusão no contexto do conjunto de dados. Note que você pode usar o banco de dados correspondente à força de trabalho ativa, `acs_emp`, ou qualquer outro subconjunto que você selecionar.

Para decidir quais variáveis utilizar, vamos ver as possibilidades dentro do conjunto de dados original:


```{r}
acs_emp %>%
  head() %>%
  kable() %>%
  kable_styling(
    full_width = F, 
    bootstrap_options = c("striped", "hover", "condensed",
                          "responsive")
    )
```

Olhando para o dataframe, percebemos que a única variável que faz sentido usar como variável resposta é a renda (`income`) dos participantes do estudo. Porém, neste caso, vamos utilizar o nível de escolaridade da pessoa como variável explicativa. 

Primeiro, vamos ver quantos níveis tem a variável `edu`:


```{r}
levels(acs_emp$edu)
```

Vemos, portanto, que essa variável possui 3 níveis: "hs or lower", "college" e "grad", que se referem a pessoas com escolaridade menor ou igual a ensino médio, cursando faculdade e já graduados, respectivamente.

O problema de pesquisa aqui é testar se a renda média dos entrevistados é a mesma para os 3 níveis analisados. Para verificar, vamos usar ANOVA:


```{r}
anova2 = aov(income ~ edu, acs_emp)
result = anova(anova2)
result
rsq = result$`Sum Sq`[1]/sum(result$`Sum Sq`)

cat(
  "Coeficiente de explicação do modelo:",
  rsq
)
```

Vemos assim que cerca de 15% da variância dos dados é devido aos diferentes níveis de escolaridade. Além disso, esse resultado é significativo para qualquer nível de significância usualmente utilizado. Dessa forma, concluímos por rejeitar a hipótese nula de que as rendas médias são iguais para os 3 grupos de escolaridade.

Vamos agora testar a igualdade das médias salariais duas a duas. Desta vez, vamos fazer isso diretamente através da função `PostHocTest`:


```{r}
PostHocTest(anova2, method = "bonferroni", conf.level = 0.95)
```

Concluímos então que:

$$ \mu_1 < \mu_2 < \mu_3, $$

em que $\mu_1$ se refere a quem tem ensino médio ou menor, $\mu_2$ é para quem está na faculdade e $\mu_3$ é para os graduados. O resultado corrobora com a ideia de que quem tem maior nível de escolaridade tem maior renda.




# Lab09: Inferência para dados categóricos


# Lab10: Regressão linear simples


# Lab11: Regressão linear múltipla



# Referências